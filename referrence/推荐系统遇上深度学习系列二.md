本pdf是公众号小小挖掘机连载的推荐系统遇上深度学习系列51-75篇的合辑。该系列还在连载中，感兴趣的同学欢迎关注下方公众号：

![](https://upload-images.jianshu.io/upload_images/4155986-c793bfe88d300871.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/430)

[TOC]



# 推荐系统遇上深度学习(五十一)-谈谈推荐系统中的冷启动

# 1、冷启动问题的分类
咱都知道，冷启动问题是推荐系统中面临的难题之一。冷启动问题主要分为以下三类：

1)**用户冷启动**:用户冷启动主要解决如何给新用户做个性化推荐的问题。

2)**物品冷启动**:物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。

3)**系统冷启动**:系统冷启动主要解决如何在一个新开发的网站上(还没有用户，也没有用户行为，只有一些物品的信息)设计个性化推荐系统。

今天咱们主要来谈谈用户冷启动和物品冷启动问题的解决。最后简要介绍一些深度学习方法的解决方案。

# 2、用户冷启动的解决方案

## 2.1 使用热门榜单

当新用户来的时候，把近一周、近一个月比较热门的item推荐给用户。使用热门榜单推荐在某些场景下也能达到很好的推荐效果。举个亲身实践的例子吧，旅游景点的推荐。毕业论文做的这方面的内容，当使用热门景点进行推荐时，其效果是好于协同过滤方法的，这主要是由于景点推荐场景中有着明显的随大流心态，用户会倾向于去大家都去的地方。

## 2.2 利用用户的注册信息

我们可以有效利用用户以下三种注册信息进行推荐：

**人口统计学信息**
人口统计学信息包括年龄、性别、职业、民族、学历、居住地等等。不同用户在一个平台上表现出的行为有可能是截然不同的。举个例子（下面的也是我的猜测），在视频推荐中，年轻人可能更偏向青春偶像剧，年纪稍微大一点的可能会喜欢《乡村爱情》之类的剧集。再比如，在外卖平台上，女性点奶茶会明显多于男性。使用这种信息的话，就需要对每种商品的合适人群进行一定的统计，随后再配合热门榜单进行推荐同样可以达到不错的推荐效果。

####用户选择的兴趣标签
在某些网站注册时，往往会要求用户选择一些自己感兴趣的标签，如下面网易云音乐注册时，让用户选择喜欢的音乐的语种等等：

![](https://upload-images.jianshu.io/upload_images/4155986-a652bc04997ca708.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**用户绑定的其他平台账户信息**
现在大多数网站都可以通过第三方平台如微信、QQ、微博进行登录。如在CSDN上，可以选择的登录方式有：

![](https://upload-images.jianshu.io/upload_images/4155986-854db166665c5356.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如果用户使用这些账号进行登录，我们可以通过账号信息追溯用户在其他平台上的行为，作为冷启动的参考。我们甚至可以通过其社交网络网络数据来进行推荐。比如两个用户都是通过微博登录的，而他们在微博中是互相关注的状态，那么我们就可以通过其好友的行为来进行推荐。

## 2.3 利用同平台其他产品中的行为进行推荐
与第三方登录不同。这里说的是使用同平台其他产品中的行为进行推荐。最典型的例子就是腾讯。如对QQ音乐的新用户进行推荐，可以利用其它腾讯平台的数据，比如在QQ空间关注了谁，在腾讯微博关注了谁，更进一步，比如在腾讯视频刚刚看了一部动漫，那么如果QQ音乐推荐了这部动漫里的歌曲，用户会觉得很人性化。

## 2.4 利用用户手机的IMEI号进行冷启动

IMEI号的全称是国际移动设备识别码（International Mobile Equipment Identity，IMEI），即通常所说的手机序列号。Android手机开放的比较高，在安装自己的手机APP时，可以了解到该手机上还安装了什么其他的app。我们同样可以基于统计的方式判定一个用户的大致画像，比如一个用户安装了美丽说、蘑菇街等应用，基本可以判定该用户是一个女性用户。更进一步，通过IMEI号，用户在手机上的行为也是可以获取的。比如大家在淘宝浏览了某些物品后，今日头条、虎扑等就马上有了相应的广告推荐。


# 3、物品冷启动的解决方案

## 3.1 利用物品的内容信息

该方法主要通过物品描述等文字中的语义来计算其相似度，对新闻等对于时效性有很高要求的领域来说比较常用。其基本思路是利用物品的内容信息计算物品的相关程度。比如将物品转换成关键词向量，通过计算向量之间的相似度（例如计算余弦相似度），得到物品的相关程度。
在《推荐系统实践》一书中，给出了一些常见的物品内容信息：

![](https://upload-images.jianshu.io/upload_images/1668945-356ed5f8fbfa7346.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/981)

再比如，在电商推荐领域，可以通过一些标签信息来计算物品之间的相似程度。如用户在购买过火箭队球衣之后，可以推荐给其哈登的新球鞋，因为这些物品拥有共同的标签，如哈登、火箭队等等。

## 3.2 利用专家标注信息

很多系统在建立的时候，既没有用户的行为数据，也没有充足的物品内容信息来计算物品相似度。这种情况下，很多系统都利用专家进行标注。以Pandora电台为例，Pandora雇用了一批音乐人对几万名歌手的歌曲进行各个维度的标注，最终选定了400多个特征。每首歌都可以标识为一个400维的向量，然后通过常见的向量相似度算法计算出歌曲的相似度。


# 4、基于深度学习的方法

基于深度学习的冷启动方案也有不少了。这里咱们简单谈一谈。在《推荐系统与深度学习》一书中，介绍了两个案例。分别是使用CNN对音频流派进行分类以及人脸魅力值打分在视频推荐中的应用，感兴趣的同学可以看一下原书，这里就不再赘述。

在电商领域的推荐中，常见的召回策略是通过计算物品之间embedding的相似度。对于新加入的物品，可以使用其side-information的embedding来近似代替物品的embedding，从而进行相似度的计算。在阿里的两篇文章《Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba》和《Learning and Transferring IDs Representation in E-commerce》提出了相应的解决方案，大家可以参考下。

总之，基于深度学习方法的冷启动解决方案，大都集中在解决物品冷启动问题上，其基本的思路是通过深度学习方法来计算新物品和已有物品之间的相似性。这里咱们只是抛砖引玉，感兴趣的同学可以查阅更多的资料。

## 参考资料
1、项亮《推荐系统实践》
2、《推荐系统与深度学习》
3、https://www.zhihu.com/question/19843390
4、https://www.jianshu.com/p/97e46f933010
5、Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba
6、Learning and Transferring IDs Representation in E-commerce

# 推荐系统遇上深度学习(五十二)-基于注意力机制的用户行为建模框架ATRank

本文来介绍一下阿里巴巴数据技术团队与北京大学共同提出的 ATRank ，ATRank是基于注意力机制的用户异构行为建模框架，可应用于推荐系统中，一起来了解一下吧。

论文名称《ATRank: An Attention-Based User Behavior Modeling Framework for Recommendation》

论文地址：https://arxiv.org/abs/1711.06632

示例代码地址：https://github.com/jinze1994/ATRank/tree/master/atrank

# 1、背景

正如一个单词可以通过其上下文来表示，那么一个用户也可以通过其过往的行为序列来表示。但随着技术的发展，越来越多样化的用户行为可以被捕捉并保存在数据库中，使得用户行为表现出异构性，高度多样性。以电商领域的推荐为例、一个用户可能浏览、购买、收藏商品，领取、使用优惠券、点击广告、搜索关键词、写评论或者观看商家提供的商品介绍视频等等。这些不同的行为为我们更全面的理解一个用户提供了不同的视角。

面对用户如此多样化的行为，要想做到更精确的推荐，很大的挑战来自于能否对用户的异构行为数据进行更精细的处理。在这样的背景下，本文提出一个通用的用户行为序列建模框架，试图融合不同类型的用户行为，并以此框架进行推荐任务。

# 2、模型框架

我们先来看一下本文提出的用户行为建模框架的整体架构：

![](https://upload-images.jianshu.io/upload_images/4155986-423760220a779d6f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

该框架分为以下几个模块：原始特征空间(raw feature spaces)、行为嵌入空间(behavior embedding spaces)、隐语义空间(atent semantic spaces)、行为交互层(behavior interaction layers)、下游网络层(downstream application network)。

接下来，我们首先定义一下用户行为序列表示，随后对上面几个模块进行依次介绍。

## 2.1 用户行为序列定义

用户行为序列被定义为U={(a<sub>j</sub>,o<sub>j</sub>,t<sub>j</sub>)|j=1,2,...,m}。其中，每一个行为被表示称三元组(a,o,t)。a代表用户的行为种类，o代表该行为发生时的一些特征表示，不同的行为种类的话，这里的特征可能是不同的。举个简单的例子，如果一个用户行为是购买行为，那么特征更多的是有关这个购买的物品的，如果一个用户行为是搜索关键词，那么特征更多是关于这个关键词的。t代表用户行为发生时的时间戳。

## 2.2 Raw Feature Spaces

在这一层中呢，会对用户行为进行进行分组，主要是按照不同的行为目标实体，而非不同的用户行为。还是举例说明一下。如浏览、购买、收藏商品，这些都是商品相关行为、领取、使用优惠券时优惠券相关的行为等等。那么这里划分不是按照浏览、购买、收藏商品去进行划分，而是根据商品行为、优惠券行为去进行划分。

划分后的结果表示为G={bg<sub>1</sub>,bg<sub>2</sub>,...,bg<sub>n</sub>}。这样，在每一个组bg<sub>i</sub>里，特征o都是相同的。

## 2.3 Behavior Embedding Spaces

在这一层，要将用户的行为转换为嵌入向量。对于用户在bg<sub>i</sub>这一组中的某一个行为(a<sub>j</sub>,o<sub>j</sub>,t<sub>j</sub>)，我们会将a<sub>j</sub>、o<sub>j</sub>、t<sub>j</sub>分别转换为嵌入向量。

![](https://upload-images.jianshu.io/upload_images/4155986-ea9c4db564ce1620.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里按照不同的组bg<sub>i</sub>进行划分的主要原因是针对不同的组，特征o是不同的。

下面主要来讲一下对时间t的编码方式，t是行为发生时的时间戳，首先会计算与当前时间的一个时间间隔，但此时仍然是一个连续变量，不好将其转换为embedding表示。这里文中提到了一种离散化的表示方法，将时间间隔按照如下的区间进行离散化：

![](https://upload-images.jianshu.io/upload_images/4155986-f72d37aa0a5a0279.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在得到每个行为的embedding表示后，可以根据组别，得到每个组的embedding表示：

![](https://upload-images.jianshu.io/upload_images/4155986-de6c844bcfea4bac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中：

![](https://upload-images.jianshu.io/upload_images/4155986-d02f8fdb96687845.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

值得注意的是，每组得到的embedding可能是不同长度的，一是由于用户行为在每组下面的序列长度是不同的，二是由于不同的行为所包含的信息量也是差别很大的，如用户的一次购买行为，所能体现出的偏好信息是比一次关键词搜索是更多的，因而往往需要更长的embedding。

此外，这里的u<sub>bg1</sub>,u<sub>bg2</sub>,...,u<sub>bgn</sub>并非是一个向量，而是一组向量，即仍然是每一个行为对应一个向量，示意如下：

![](https://upload-images.jianshu.io/upload_images/4155986-ae293ffb888cd25d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在不同组中，有些特征的embedding可能是共享的，如店铺ID、品类ID等等，但需要注意的是，对于时间的embedding在不同组是不共享的。

## 2.4 Latent Semantic Spaces

由于每组中行为的最终embedding长度不一，同时所处的向量空间也不同。这里其实就是通过线性变换来将其统一到同一个语义空间。

具体来说：

![](https://upload-images.jianshu.io/upload_images/4155986-68340f89535bb959.png?imageMogr2/auto-duogzzzzorient/strip%7CimageView2/2/w/1240)

然后，在得到S之后，再通过多个投影矩阵，将S映射到多个不同的语义空间。

![](https://upload-images.jianshu.io/upload_images/4155986-7e2b124738f3125b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

同样，这里的过程表示如下：

![](https://upload-images.jianshu.io/upload_images/4155986-0a81fb486a7bcbc7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


## 2.5 Self-Attention Layer

接下来，对每一个语义空间中的向量，经过一层self-attention layer，Self-Attention Layer想必大家都很熟悉了，在前面的文章中，咱们用excel将整个过程详细地捋了一遍，感兴趣的话可以查看原来的论文：

https://www.jianshu.com/p/2b0a5541a17c

在self-attention中，要分别输入queries和keys，queries用来计算Q、keys用来计算K和V。这里的的queries是S<sub>k</sub>，而keys是S，过程表示如下：

![](https://upload-images.jianshu.io/upload_images/4155986-fda3f9caf3fd46f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

写到这里，用户行为建模的过程就结束了，来回顾一下上面的整个流程(下图中每一个单元格代表的是一个向量)：

![](https://upload-images.jianshu.io/upload_images/4155986-51a78839e53e5cb0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里还是想说，上面的过程仅仅是我的个人理解，网上的参考资料或者给出的示例代码中，均无法提供很好的参考依据。所以如果大家有不同的见解，欢迎与我一起讨论。

## 2.6 Downstream Application Network

在对用户行为进行建模之后，接下来我们就可以做许多下游任务了。文中是以推荐任务为例。这里仍然使用类似于self-attention的过程：

![](https://upload-images.jianshu.io/upload_images/4155986-5e0b4facedca7573.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-8c4b735bb88f19f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

数学公式是不是看着头大？还是用excel来表示一下吧，假设下游任务是一个物品相关的行为：

![](https://upload-images.jianshu.io/upload_images/4155986-687b965898aac7e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

好了，本文的介绍就到这里了，本文的重点是对用户行为序列建模的方法的介绍，对用户行为序列进行建模后，可以用于多种不同的下游任务，相比于DIN、DIEN和DSIN，它考虑了用户更多样的用户行为，但由于本文的时间比较早，所以也没有和DIN等模型进行对比，实践中感觉是可以尝试一下的。

# 推荐系统遇上深度学习(五十三)-DUPN：通过多任务学习用户的通用表示

本文介绍的文章题目是：《Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks》

论文的下载地址为：https://arxiv.org/pdf/1805.10727.pdf

视频介绍：https://yq.aliyun.com/video/play/1377?do=login&accounttraceid=2a655d82-06ce-4c03-a7bf-9e7c8f36b76e


本文以淘宝搜索和推荐场景为背景，通过一个多任务模型来学习用户的通用表示，并对比了多任务模型和单任务模型的一些实验效果，并对多任务模型以及模型迁移等方面给出了一些经验介绍。咱们一起来看看。

# 1、多任务学习的优势

我们为什么要使用多任务学习呢？或者说，多任务学习相比于单任务学习有哪几方面的优势呢？总结主要有两点：
1）使用一个多任务学习模型，可以共享一部分网络结构，相比于使用多个单任务学习模型，其总体的网络结构大小更小，在线CPU使用率更低，对于在线服务更加友好，可以保证线下服务性能的稳定性，支撑更大的QPS。同时，对于存储资源也会大大的节省，我们没必要为每一个任务保存一份embedding词表，而只需保存一份即可。
2）在淘宝中，使用多任务学习，可以学习到更通用的用户、商品的向量表示，这些向量可以更方便地迁移到其他任务中。

基于以上两点，接下来我们首先介绍本文的多任务学习模型，然后详细介绍下多任务模型和单任务模型的效果，以及模型的迁移能力，最后，介绍下一些多任务模型使用上的经验。

# 2、多任务模型

本文提出的模型称为DUPN网络（ Deep User Perception Network），其整体的架构如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-29f92ab544bdb8b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，一共分为五层，行为序列层、Embedding层、LSTM层、Attention层、下游多任务层。接下来，我们分别介绍这几部分。

## 2.1 行为序列层

模型的输入是用户的行为序列x = {x<sub>1</sub>,x<sub>2</sub>,...,x<sub>N</sub>},行为序列中的每一个行为都有两部分组成，例如第i个行为x<sub>i</sub>被表示成<item<sub>i</sub>,property<sub>i</sub>>,item<sub>i</sub>表示这次行为对应的淘宝中的商品，不仅仅是商品本身，还包含商品的一些side-information，比如店铺ID、品牌、品类、标签等等。property<sub>i</sub>表示此次行为的一些属性，比如场景（scenario，如搜索、推荐、聚划算等等场景）时间、类型（点击、购买、加入购物车等等）。

## 2.2 Embedding层

在定义好模型的输入之后，输入大多是ID类特征，因此通过Embedding层转换为对应的Embedding：

![](https://upload-images.jianshu.io/upload_images/4155986-c3e629701ba46d04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

用户的每个行为被表示为：

![](https://upload-images.jianshu.io/upload_images/4155986-d8d4c06e2356c328.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对item feature来说，包括商品id、店铺、品牌、品类、标签，这些在淘宝中词表的大小分别为1G、1M、10M、1M、100K，对应的embedding的长度分别为32、24、24、16和28。这些有的是multi-hot的，比如商品可能会有多个标签，应该会通过pooling操作进行转换。

而对于行为property来说，场景、时间和类型的embedding的长度均为16。因此最终每一个行为的Embedding长度为32 + 24 + 24 + 16 + 28 + 16 * 3 = 172。

## 2.3 LSTM层

得到了每一个行为的Embedding表示之后，首先通过一个LSTM层，把序列信息考虑进来，LSTM层的表示如下：

![](https://upload-images.jianshu.io/upload_images/4155986-795a6360692b9206.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

每个hidden state的计算如下：

![](https://upload-images.jianshu.io/upload_images/4155986-cbae3950fe7767de.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

输出的每个hidden state是128维的向量。

## 2.4 Attention层

在LSTM层之后，通过Attention层来决定行为的重要程度。举个简单的例子来说明为什么要用Attention层。例如，某用户点击浏览一条连衣裙，然后购买了一个手机，浏览了一些扫地机器人、笔记本电脑等。如果此时该用户输入搜索query为iphone，那么用户行为中关于服饰的记录重要性明显降低，因为这些记录并不能反映该用户当前的兴趣，而之前关于手机的行为记录能更多的表达用户当前的兴趣。

那么Attention层的结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-36160c17b36e39c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

结合总体网络结构看看attention层：

![](https://upload-images.jianshu.io/upload_images/4155986-eb59e33ce0ac3f1c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

图中粉色和蓝色以及黑色虚线为模型的输入，粉色线代表行为behavior相关的embedding、蓝色线代表LSTM层的hidden state输出、黑色为用户和query的embedding。通过多层全连接神经网络得到权重作为输出，然后权重和对应的hidden state进行加权平均，得到attention层的输出，同样是一个128维的向量。

经过attention层得到的128维的向量，拼接上128维的用户向量，最终得到一个256维向量作为用户的表达。用户信息包括用户年龄、性别、购买力、购买偏好等等。

## 2.5 下游任务

下游任务这里介绍了4个，分别是CTR、L2R(Learning to Rank)、用户达人偏好FIFP、用户购买力度量PPP。感觉前两个是主要的任务，后两个任务主要用于使得学到的用户表示更加通用。除此之外，为了验证模型的迁移能力，还介绍了第五个任务，即来预测用户对某个店铺的偏好，该任务并非和上述四个任务同时学习，而是取上述四个任务学习之后的用户表达进行学习，验证其是否可以直接使用在新任务中。

**2.5.1 点击率CTR预估**

![](https://upload-images.jianshu.io/upload_images/4155986-be0daf86b618ffb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里输入有两部分，一是我们刚才得到的256维的用户向量表示，另一个是Item的feature对应的128维向量表示，item的向量表示，还是刚刚说到的5部分，分别是商品id、店铺、品牌、品类、标签，对应的embedding长度分别是32、24、24、16和28，这里和Embedding层的embedding是共享的。

CTR预估任务的loss是logloss：

![](https://upload-images.jianshu.io/upload_images/4155986-e734db2e9b26d3f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**2.5.2 排序权重学习Learning to Rank**

这里想要学习的是一些用于排序的特征的权重，部分特征如下：

![](https://upload-images.jianshu.io/upload_images/4155986-0decd6859a8a288d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过权重的学习，对不同的排序特征进行加权，来使得转化率最大化，网络结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-27bab405ab5a0168.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里的loss如下：

![](https://upload-images.jianshu.io/upload_images/4155986-ff7f91fea0e7cba2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里y<sub>i</sub>取值为1或-1，代表第i个样本的label，n<sub>i</sub>是基于不同的行为类型的样本权重，r<sub>i</sub>是m维的排序特征，weight(rep<sub>i</sub>;θ)是上图结构中左边部分的输出。也是m维的。这里m为26。

**2.5.3 用户达人偏好预测FIFP**

这一部分的结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-07865914c5618b01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

预测用户是否会follow某一些达人，输入分别是刚才得到的256维的用户表示以及一些达人的特征。这里的损失同样为logloss。


**2.5.4 用户购买力度量PPP**

这里将用户的购买力分为7档，来预测用户的购买力属于哪一档。

![](https://upload-images.jianshu.io/upload_images/4155986-49e6c32adb7d0ee6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**2.5.5 店铺偏好SPP**

该部分同样是一个二分类任务，结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-055240dbce3de81b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这一部分在后面的实验结果中，咱们进一步介绍。

# 3、实验结果

这一部分介绍模型的一些实验结果，主要分为四部分，首先对比了DUPN和一些Baselines的效果比较，随后对比了多任务学习和单任务学习效果，然后通过第五个任务验证了模型的迁移能力，最后对attention进行了简单的分析。

## 3.1 DUPN VS Baselines

这里选取的Baselines有四种，分别是Wide、Wide & Deep、DSSM和CNN-max，而DUPN方面，又分了五种情形，分别计作DUPN-nobp/bplstm/bpatt/all/w2v。DUPN-nobp表示不使用behavior property；DUPN-bplstm表示只在lstm部分使用behavior property；DUPN-bpatt表示只在attention部分使用behavior property；DUPN-all即我们刚才所描述的整个模型框架。前面四种中，embedding都是通过end-2-end的方式进行训练的，即随机初始化embedding，然后根据模型一起进行训练，而DUPN-w2v对embedding进行预训练。

因此，一共9种模型，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b8c423bcb6d73ca4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可一看到，所有任务上，都为DUPN-all的效果最好。

## 3.2 多任务学习 VS 单任务学习

多任务学习模型和各个单任务学习模型在测试集上的效果对比如下：

![](https://upload-images.jianshu.io/upload_images/4155986-c7d7ef1373eaa1ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，尽管在训练集上的误差多任务学习模型会偏大，但是在测试集上的效果，多任务学习模型反而更好，模型的泛化能力得到了提升。

## 3.3 模型迁移能力验证

接下来通过店铺偏好实验来验证一下模型的迁移能力。在训练完包含前4个任务的多任务模型之后，有下面几种方法应用于第5种任务上：

End-to-end Re-training with Single task (RS)：使用DUPN的网络结构单独训练这一个新任务。
End-to-end Re-training with All tasks (RA)：使用DUPN的网络结构重新训练5个任务
Representation Transfer (RT)：将学习到的用户表示以及店铺属性作为输入，训练一个简单的网络，这里用户表示不会被更新 
Network Fine Tuning (FT)：将学习到的用户表示以及店铺属性作为输入，训练一个简单的网络，这里用户表示会随着网络训练而Fine Tuning。

上述四种方法的训练过程如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-00f50f7b0af02c43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中横坐标为训练轮次，纵坐标为AUC值。效果最佳的为绿色曲线FT，一方面FT收敛较快，另一方面其最终AUC值也最高，为0.675左右。这说明之前的网络已经达到了较好的训练效果，进行一些微调后便可以很快的得到最终结果。而黑色曲线RA虽然收敛速度较慢，最后仍然可以达到和FT同样高的AUC值。但显而易见FT的代价较低。

## 3.4 用户Attention分析

用户Attention分析从两方面进行，一是搜索关键词时和用户历史行为的相关性：

![](https://upload-images.jianshu.io/upload_images/4155986-4cb6022dd1822d25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

颜色越深表示相关性越高，可以看到，用户搜索laptop时， 那么attention更多的会集中在耳机、手机之类商品，而搜索连衣裙T恤之类，服饰相关的类目会起到比较大的作用。

第二个是不同行为类别的attention：

![](https://upload-images.jianshu.io/upload_images/4155986-fdb5034731155821.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

整体来说，用户的成交行为重要性最高，高于点击、加购物车和收藏行为。但比较有趣的一点是，用户越近的一些点击行为越能反映用户的兴趣，但是最近的成交行为并不能反映。这和大家的认知相同，当用户购买了某件商品后，近期可能不会再购买该类别商品，因此颜色较浅，相反，几个小时以前或者几天以前的购买行为能更反映用户兴趣。

## 3.5 线上A／B test实验

将该模型应用于线上的实验，各种指标都有明显提升：

![](https://upload-images.jianshu.io/upload_images/4155986-776fbdcc33b85f24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 4、多任务模型使用技巧

最后，论文还讲解了两点多任务模型的使用技巧，一是模型的更新，二是模型的拆分。

## 4.1 日级增量更新

随着时间和用户兴趣的变化，ID特征的Embedding需要不断更新，但不能每次都重新训练模型，因为这大概需要耗费4天左右的时间。因此通常的做法是每天使用前一天的数据做增量学习，这样一方面能使训练时间大幅下降，能在一天内完成；另一方面可以让模型更贴近近期数据。

## 4.2 模型拆分

模型拆分的示意图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b2028a08da438244.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

由于CTR任务是point-wise的，如果有1w个物品的话，需要计算1w次结果，如果每次都调用整个模型的话，其耗费是十分巨大的。但其实，user Reprentation只用计算一次就好。因此我们会将模型进行一个拆解，使得红色部分只计算一次，而蓝色部分可以反复调用红色部分的结果进行多次计算。

## 4.3 BN问题
这是论文中没有但是在视频中有所提及的。Batch normalization能很好的提升模型效果，使AUC显著提升。但需要注意的是，训练样本中BN记住的离线均值和方差和在线数据中一定要保持一致。举例来说，在训练样本中会做各种过滤和采样，例如把点击和成交样本采样，那么这样会导致某些维度的均值会远远高于实际线上的均值，虽然在测试集上的AUC也能提升，但这对在线效果非常不利。

# 5、总结
这篇文章感觉非常有借鉴意义。不仅验证了多任务学习相对于单任务学习的优势，同时为建模用户行为提供了新的思路。除此之外，还介绍了阿里在模型应用上的一些经验，值得借鉴。

这篇文章发出时可能还没有Transformer，我觉得将LSTM层换成一层Transformer也许效果会有提升，感兴趣的同学可以试一试。


# 推荐系统遇上深度学习(五十四)-使用GAN搭建强化学习仿真环境

[](https://upload-images.jianshu.io/upload_images/4155986-b9f8481b4069dd95.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

京东对于强化学习感觉非常执着啊，咱们在之前已经介绍过三篇京东公开出来的强化学习文章了。今天咱们再来介绍一篇，这一篇中，重点介绍了如何使用GAN搭建一个强化学习的仿真环境。一起来看下吧。

论文名称：《Toward Simulating Environments in Reinforcement Learning Based Recommendations》

论文下载地址：https://arxiv.org/abs/1906.11462

# 1、背景
在电商领域呢，使用强化学习做推荐，可以带来两方面的好处：
1）通过用户状态的改变，可以不断地实时调整推荐策略
2）可以优化用户的长期收益，例如整个session的收益，而非推荐单个物品的收益

但是，使用强化学习也有一定的限制，主要有：
1）我们通常使用用户对推荐结果的实时反馈来训练强化学习推荐模型，最为有效的方法是使用线上的A／Btest来产生有效的数据，但是使用A／B来收集数据通常需要几周的时间，同时部署一个新的方法也需要工程上耗费更多的资源和精力。
2）同时，如果一个推荐系统没有被充分训练好的话，A／B实验往往会对用户的体验造成一定的损害。
3）在电商领域，商品数量和用户数量都是数目巨大的，导致整个的状态空间和动作空间十分巨大，因此需要极大规模的数据量来保证模型的鲁棒性。尽管日志数据数量非常多，但是对于每个用户来说，数量是极少的。

因此，为了克服上述挑战，解决数据量问题以及线下充分训练问题，这里我们提出了一个基于GAN的强化学习仿真环境。一起来看一下吧。

# 2、问题陈述

作为强化学习的问题陈述，当然少不了四大基本元素：状态空间、动作空间、奖励、状态转移概率。当然有时候还有折扣系数等等，这里不做介绍。

**状态空间S**：这里我们定义的用户状态s={i<sub>1</sub>,i<sub>2</sub>,...,i<sub>N</sub>},是用户近期浏览过的N个商品，以及对应的反馈。

**动作空间A**：动作空间就是可以推荐的物品集合，这里一次动作a只推荐一个商品。

**奖励R**：当系统基于用户状态s作出动作a时，用户会对推荐的物品作出反馈，这里的反馈包括跳过、点击或者购买该商品，而不同的反馈对应的奖励r(s,a)也是不同的。

**状态转移概率P**：这里的状态转移概率是确定的，当s={i<sub>1</sub>,i<sub>2</sub>,...,i<sub>N</sub>}，动作为a时，转移到的状态s'={i<sub>2</sub>,...,i<sub>N</sub>,i<sub>a</sub>}，这里感觉论文写的不太准确，因为状态不仅包括推荐了那个商品，还包括用户的反馈，所以这里可能稍微和论文有点出入。

# 3、基于GAN的仿真环境概述

基于上述的问题定义，本文提出的基于GAN的仿真系统框架如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-65edb27514f663bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 3.1 Generator
Generator的整体结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-0bd64eea1fad2624.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

Generator是一个encoder-decoder结构，输入的话是用户的浏览序列，即当前的状态，包含N个商品以及用户对商品的反馈。每一时刻的输入包含两部分：

![](https://upload-images.jianshu.io/upload_images/4155986-75f296773b5bc069.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中e<sub>n</sub>是i<sub>n</sub>对应的商品的embedding，这里的embedding论文中提到说是经过预训练得到的（感觉按照论文的意思，这块不会随着模型训练进行fine-tuning）。f<sub>n</sub>是一个反馈类型展开后的one-hot向量。接下来，反馈类型也将转换为对应的embedding：

![](https://upload-images.jianshu.io/upload_images/4155986-789acc487d0d0513.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里使用tanh进行激活的原因是e<sub>n</sub>中每个元素的取值范围是（-1，1），那么经过转换后，输入变为：

![](https://upload-images.jianshu.io/upload_images/4155986-8378c4dabe051127.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来是一个GRU层，经过GRU层之后，得到最终的hidden state输出为h<sub>n</sub>，将其视为用户当前的偏好表示：

![](https://upload-images.jianshu.io/upload_images/4155986-a096c64aef204b70.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

Deocder阶段的目标是预测下一个要推荐给用户的商品，将用户当前的偏好表示p<sup>E</sup>作为输入，经过多层全连接神经网络后得到向量输出，G<sub>θ</sub>(s)。这里是得到的一个向量，要想得到一个具体的商品，可以跟所有商品的embedding计算相似度，并选择一个相似度最高的商品。

好了，到目前为止，我们已经介绍了Generator的结构，关于如何训练Generator将在3.3节介绍。接下来先介绍Discriminator的结构。

## 3.2 Discriminator
Discriminator的整体结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-a58a908396389bd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，Discriminator左下角的输入部分与Generator是一样的结构，但是与Generator的参数并不相同。GRU部分最后的输出计作p<sup>D</sup>。

而右下角的部分则把真实的action对应的item的embedding或者Generator生成的G<sub>θ</sub>(s)作为输入，经过两层的全连接层得到输出e<sup>D</sup>。

将p<sup>D</sup>和e<sup>D</sup>进行连接之后，再经过两层全连接层，得到Discriminator的输出，长度为2 * K。其中K代表用户反馈类型的种类：

![](https://upload-images.jianshu.io/upload_images/4155986-ab2036087bd868f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

输出的结果是经过softmax之后的结果：

![](https://upload-images.jianshu.io/upload_images/4155986-7bebfc474c0231b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

输出中的前K维表示，如果这个输入是真实的商品（这里的真实商品即用户在当前状态下，下一个实际浏览的商品）的话，用户的每种反馈的概率，后K维表示，如果这个输入是Generator产生的话，用户的每种反馈的概率。

接下来，咱们介绍如何对Generator以及Discriminator进行训练。

## 3.3 模型训练

对于Discriminator来说，咱们这里共有两个目标，判断这个输入是真实的商品还是Generator产生的，同时，判断用户可能作出的反馈。因此，损失函数也包含两部分。

第一部分的损失函数，我们首先要计算Discriminator把输入判作真实或虚假概率。判作真实的概率计作：

![](https://upload-images.jianshu.io/upload_images/4155986-10af9f0b2de0dbcf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

即输出的前K项的和，而判作虚假的概率是：

![](https://upload-images.jianshu.io/upload_images/4155986-06177db06e03de7f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

即输出的后K项的和。有了两部分的概率，可以使用logloss来计算损失：

![](https://upload-images.jianshu.io/upload_images/4155986-4f7ef17247311d76.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而为了估计用户每种反馈的概率，第二部分的损失函数设计如下：

![](https://upload-images.jianshu.io/upload_images/4155986-10b7a70b8b0ec462.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

第二部分的损失函数又包含两个小部分，这两个小部分都是交叉熵损失，代表用户真实的反馈和Discriminator得到的用户反馈类型分布的差距。如果输入是一个真实的商品a的话，那么会对应一个用户真实的反馈，可以依此来指导模型的训练，如果模型输入是Generator的输出的话，同样会使用用户在下一个商品上的真实反馈指导模型训练，这样相当于进行了一定的数据增强，增加了Discriminator的判别能力，进而提升了Generator的生成能力，不过这部分的贡献需要乘上一个打折系数。

这里为什么说在一定程度上进行了数据增强呢？暂时还没有想明白，欢迎大家在下方留言，一起交流讨论。

进而，Discriminator总的损失计算如下：

![](https://upload-images.jianshu.io/upload_images/4155986-cc1ec6c1669bbce1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于Generator来说，同样有两部分的损失，一是希望能尽可能骗过Discriminator，使得Discriminator将Generator产生的判别为假的概率越低越好：

![](https://upload-images.jianshu.io/upload_images/4155986-7c437c122622193b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

二是希望产生的向量G<sub>θ</sub>(s)，与真实序列中下一个商品的向量距离越近越好，这里距离使用欧氏距离计算：

![](https://upload-images.jianshu.io/upload_images/4155986-858c320b0d7f794b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因此，总的损失计算结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-85ad5f940d25d0bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

好了，模型就介绍到这里了，后面的实验部分咱们就略过了，感兴趣的同学可以看一下。

# 4、仿真环境使用(猜测)

那么得到一个仿真环境之后，该怎么利用呢？论文这一块没有明确的说明，但可以知道的是，既然是一个仿真环境，那么是为了产生更多的训练数据，来使得真正的强化学习推荐模型训练得更加充分，那么可能的做法就是在G和D都训练充分之后，通过G产生一个推荐的item（这个item可能是与Generator产生的向量最为接近的item），然后通过D的前K维输出来得到用户最可能的反馈，并将其作为一条训练数据来训练真正的强化学习模型。这一块也仅是猜测，同样欢迎大家留言讨论！



# 推荐系统遇上深度学习(五十五)-[阿里]考虑时空域影响的点击率预估模型DSTN

![](https://upload-images.jianshu.io/upload_images/4155986-c793bfe88d300871.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/430)


![](https://upload-images.jianshu.io/upload_images/4155986-ab3ca208a72b403b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文题目为：《Deep Spatio-Temporal Neural Networks for Click-Through Rate Prediction》

论文的下载地址为：https://arxiv.org/abs/1906.03776

题目貌似很玄乎，什么是时空域？我们可以分解为**空间域(spatial domain)**和**时间域(temporal domain)**。空间域的意思即是说，在一屏的推荐中，内容是相互关联的，当推荐了第一条广告之后，第一条广告会对第二条广告的点击率产生影响，从而影响第二条推荐的广告。时间域的意思即是说，用户之前的点击或未点击的广告会影响当次的推荐。在本文中，阿里的算法人员同时考虑空间域信息和时间域信息，来进行广告的点击率预估，一起来看下是如何做的吧。

# 1、背景

CTR预估问题在广告领域十分重要，吸引了工业界和学术界学者的研究。之前我们也介绍过许多比较成功的方法，如LR、FM、Wide & Deep、DeepFM等。

但上述的方法，存在一个共同的问题，即当我们要预估对一个广告的点击概率时，只考虑该广告的信息，而忽略了其他广告可能带来的影响。如用户历史点击或者曝光未点击的广告、当前上下文已经推荐过的广告等。因此，将这些广告作为辅助信息，加入到模型中，也许可以提升CTR预估的准确性。

总结一下，辅助广告总共有三种类型：上下文广告、用户点击过的广告、用户未点击的广告，如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-fb04933b9fc020e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里还是想强调一下上下文广告这个概念，之前的模型可能一次计算所有广告的点击率，然后按点击率进行排序，取top-K进行展示。但这里我们把一次推荐K个广告过程看作K个单次推荐的过程集合。先推荐第一个位置的广告，再推荐第二个位置的广告，，依次类推。在推荐第三个广告时，推荐的第一个广告和第二个广告便是我们这里所说的上下文广告。

为了将这些信息加入到模型中，必须要注意以下几点：

1）每种类型的辅助广告数量可能相差很多，模型必须适应这些所有可能的情况。
2）辅助的广告信息可能与目标广告是不相关的，因此，模型需要具备提取有效信息，而过滤无用信息的能力。举例来说，用户点击过的广告可能有咖啡广告、服装广告和汽车广告，当目标广告是咖啡相关的广告时，过往点击中咖啡相关的广告可能是起比较大作用的信息。
3）不同类型的辅助广告信息，有时候起到的作用可能是不同的，模型需要能够有能力对此进行判别。

总的来说，就是模型需要有能力有效处理和融合各方面的信息。

本文提出了DSTN（Deep Spatio-Temporal neural Networks）模型来处理和融合各种辅助广告信息，下一节，咱们就来介绍一下模型的结构。

# 2、模型架构

这里讲了三种不同的DSTN的架构，分别是DSTN - Pooling Model、DSTN - Self-Attention Model和DSTN - Interactive Attention Model。但这三种模型的Embedding部分是同样的，所以咱们先讲Embedding层，再分别介绍几种模型的结构。

## 2.1 Embedding Layer

Embedding Layer的结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-391fca49f76b9f84.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，输入有四部分信息，分别是目标广告的信息、上下文广告信息、点击广告信息、曝光未点击广告信息。目标广告信息包括用户特征、query特征（如果是搜索场景的话）、目标广告特征；上下文广告信息包括上下文广告特征；用户点击过和未点击过的广告信息包括广告特征以及对应的query特征。

这些特征可以归为三类：

**单值离散特征**：如用户ID、广告ID等，这类特征直接转换为对应的Embedding。

**多值离散特征**：如广告的标题，经过分词之后会包含多个词，每个词在转换为对应的Embedding之后，再经过sum pooling的方式转换为单个向量。

**连续特征**：对于连续特征如年龄，这里会进行分桶操作转换为离散值，然后再转换为对应的Embedding。

不同的特征转换成对应的Embedding之后，进行拼接操作，如目标广告信息中，会将用户ID、用户年龄、广告ID、广告名称等等对应的Embedding进行拼接；上下文广告信息中的每一个广告，会将广告ID和广告名称对应的Embedding进行拼接等等。

最终，对目标广告信息会得到一个t维的vector，计作x<sub>t</sub>;对于上下文广告信息，我们会得到n<sub>c</sub>个c维的vector，每一个计作x<sub>ci</sub>;对于点击广告序列，我们会得到n<sub>l</sub>个l维的vector，每一个计作x<sub>lj</sub>;对于未点击序列，会得到n<sub>u</sub>个u维的vector，每个计作x<sub>uq</sub>。

介绍完了Embedding，接下来介绍几种不同的上层结构。

## 2.2 DSTN - Pooling Model

第一种结构称为DSTN - Pooling Model，其模型结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-7721a6b1b151f9a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这种方式就是对上下文广告序列、点击广告序列和未点击广告序列中的vector进行简单的sum-pooling，转换为一个vector：

![](https://upload-images.jianshu.io/upload_images/4155986-f9b7a965f8df7802.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

然后各部分进行拼接，经过全连接神经网络之后，在输出层经过一个sigmoid转换为点击的概率：

![](https://upload-images.jianshu.io/upload_images/4155986-2872d9e1953faffd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-b4d7864c4b189eb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-70c2ae949d8e0c78.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

损失函数的话选择logloss：

![](https://upload-images.jianshu.io/upload_images/4155986-140e9d80c43859d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这种方式，实现比较简单，但是存在一定的缺点，当对应一个广告位置，有多个候选目标广告时，只有目标广告信息x<sub>t</sub>发生变化，其他信息都没有发生变化，这说明我们添加的辅助广告信息仅仅是一个静态信息。同时，由于使用了sum-pooling的方式，一些有用的信息可能会被噪声所覆盖。举例来说，如果目标广告是咖啡相关的， 点击序列中有一个咖啡相关的广告，有10个服饰相关的广告，那么这个咖啡相关广告的信息很容易被忽略。

## 2.3 DSTN - Self-Attention Model

对于sum-pooling带来的缺陷，文中提出了第二种结构，称为DSTN - Self-Attention Model，这里的Self-Attention是针对每一种特定的辅助广告信息的，也就是说，上下文广告之间进行Self-Attention，点击广告序列之间进行Self-Attention等等。

如果是上下文广告之间进行Self-Attention，其最终输出为：

![](https://upload-images.jianshu.io/upload_images/4155986-d1615092b7b0037a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-59dbf037c3996fda.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过公式可以看出，这里并不是我们所熟知的Transformer里面的self-attention，第一次看也没注意，第二次细看才发现，所以有时候尽管名字一样，但内容也许千差万别。

这里的self-attention的含义是，将每一个广告对应的embedding vector输入到一个f中，得到一个标量输出β<sub>ci</sub>，这里的f可以是一个多层全连接神经网络。然后通过softmax归一化到0-1之间，得到每一个广告的权重a<sub>ci</sub>，随后基于权重进行加权求和。

使用self-attention的好处是可以对序列中的不同广告赋予不同的权重，能够在一定程度上解决sum-pooling的问题，但其仍然存在一定的缺陷。首先，self-attention中计算的权重，没有考虑target ad的信息，也就是说，针对不同的target ad，其attention权重保持不变。其次，归一化后的权重a<sub>ci</sub>,其求和是等于1的，这样，当所有的广告都与目标广告关系不大时，部分广告的权重由于归一化也会变得很大。最后，每种类型的辅助广告的数量也是会产生影响的，但由于对权重进行了归一化，这个信息相当于也丢失了。

## 2.4 DSTN - Interactive Attention Model

因此，再针对上面的不足，提出了DSTN - Interactive Attention Model。其模型结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-c1d50d64fe1ccd43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

相对于self-attention，这里的权重a<sub>ci</sub>没有经过归一化，其计算过程加入了目标广告的信息，计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-3ceb7c3ebfcebdf6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-f731e350f2ddefcb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样，针对不同的目标广告，不同类型的辅助广告信息的权重会不断变化，同时权重也没有进行归一化，避免了归一化带来的种种问题。

# 3、实验结果

论文对比了多种模型的实验结果：

![](https://upload-images.jianshu.io/upload_images/4155986-d201b88f29501cd9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 4、模型部署

看论文的时候，比较关心的一点就是模型的性能问题，因为模型中的一部分输入是上下文广告信息，更准确的前面推荐的广告的信息。假设我们有5个广告位需要推荐，比较容易想到的做法过程如下：

1、得到所有的候选广告集，并得到对应的特征，此时的上下文广告信息为空。
2、模型计算所有广告的点击概率。
3、选择点击率最高的一个广告。随后把这个广告加入到上下文广告信息中。
4、对于剩下的广告，再计算所有广告的点击概率。
5、重复第3步和第4步，直到得到5个展示的广告。

我们通过第2步得到了第一个位置的广告，重复执行3和4步4次得到剩下4个位置的广告。

这么做无疑是十分耗时的，线上性能难以保证。因此，文中提到了一种折中的做法，每次从候选集中选择2-3个广告。其示意图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-d4d285c18ef299e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 5、总结

感觉本文还是有一定借鉴意义的，最主要的是在推荐过程中考虑推荐结果之间的相互关系，这么做的话个人感觉可以消除点击率预估中的坑位偏置。因为如果上下文信息有两个广告的话，模型会感知到这是对第三个坑位的广告进行推荐。同时上下文信息的加入，在一定程度上也能提升推荐结果的多样性，避免太多同质信息推荐出来。上面两点是我自己的思考，感兴趣的同学可以详细阅读一下文章，与小编一起进行探讨。



# 推荐系统遇上深度学习(五十六)-[阿里]融合表示学习的点击率预估模型DeepMCP


![](https://upload-images.jianshu.io/upload_images/4155986-df28c410ef849de4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文名称是：《Representation Learning-Assisted Click-Through Rate Prediction》
论文下载地址为：https://arxiv.org/abs/1906.04365

本文的一个核心的思想是通过多任务的思路，建模特征之间的特定联系，从而提升CTR预估的效果。同时感觉将召回阶段的方法和精排阶段用到的方法融合到一个网络结构中，一起来学习一下。

# 1、背景

咱们前面也介绍过许多广告CTR预估中的常见模型了，如DeepFM、Wide & Deep。这些方法取得了一定的效果，但其存在一个弊端是仅考虑了特征与CTR之间的联系，而没有考虑特征之间存在的关系，如用户-广告 或者 广告-广告之间的关系，如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-9c2374905a69ba32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

特征之间的关系咱们举个简单的例子，如两个咖啡广告对应的Embedding，应该在空间中距离相近；而咖啡与服装的广告对应的Embedding，应该在空间中距离较远。DeepFM、Wide & Deep等方法并没有考虑这一层的关系，而仅仅考虑这些广告对应的Embedding对于CTR的影响。

基于上述的考虑，本文提出了DeepMCP模型，全拼是Deep Matching, Correlation and Prediction Model。从名字中也可以看出，该模型包含三个部分，分别是matching subnet、correlation subnet和prediction subnet。matching subnet用来建模用户和广告之间的关系、correlation subnet用来建模广告之间的关系，而prediction subnet则是用来建模特征-点击率之间的关系。

接下来咱们介绍下DeepMCP的模型结构。

# 2、DeepMCP模型结构

## 2.1 模型整体结构

模型的整体结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-ef2263360a6329cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

输入特征总体上可以分为四个部分，用户特征，如用户ID、年龄；query特征（搜索场景下），如query文本，query类别；广告特征，如广告ID，广告标题等等（图中的广告特征分为了三个部分，第一个可以理解为目标广告、其他两个是上下文广告和负样本广告，这两个只在correlation subnet中使用，后面详细介绍）；其他特征，如hour of day, day of week等等。

从图中可以看到，每一部分使用的特征是不同的，但是每一个子网络使用的embedding是共享的。

接下来，详细介绍每一部分。

## 2.2 Prediction Subnet

这里的Prediction Subnet是一个简单的DNN网络结构，输入特征包括用户特征、Query特征、目标广告特征和其他特征。

特征首先通过Embedding层转换为对应的Embedding，然后将特征进行横向拼接输入到DNN中，最后在输出层通过sigmoid函数转换为0-1之间的点击率预估值：

![](https://upload-images.jianshu.io/upload_images/4155986-2c05a90ce6c6a9a7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这一部分的损失使用logloss：

![](https://upload-images.jianshu.io/upload_images/4155986-24e204d50f143de7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.3 Matching Subnet

这里的Matching Subnet建模用户和广告之间的关系，感觉和点击率预估的任务有点重复，但思路还是不一样的。这里借鉴的是矩阵分解的思路，也就是说，如果用户点击过某个广告的话，我们就希望其对应的embedding是能够相近的：

![](https://upload-images.jianshu.io/upload_images/4155986-c29dd2991c8f5db5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如上图所示，Matching Subnet包含两部分，一部分用来计算用户的更高层表示，输入是用户特征和Query特征，输出计作v<sub>u</sub>；另一部分用来计算目标广告的更高层表示，输入时目标广告特征v<sub>a</sub>。

并通过下面的式子计算matching score：

![](https://upload-images.jianshu.io/upload_images/4155986-985c1620445b44f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

损失函数这里仍然选择的是logloss：

![](https://upload-images.jianshu.io/upload_images/4155986-ec4c6ba1770941eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

需要注意的一个点是计算用户和广告高层表示的时候，最后一层的激活函数是tanh，而非relu，这里主要的考虑是relu会导致很多位置的输出是0，这样在计算内积时，会导致内积趋近于0。

## 2.4 Correlation Subnet

这里的correlation subnet建模广告之间的关系，借鉴的是Skip-Gram的思路，将用户点击的广告序列作为一个document，并最大化下面的log likelihood：

![](https://upload-images.jianshu.io/upload_images/4155986-5492a28ce3ae5ebf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

实现Skip-Gram有很多种方法，相信大家也有所了解，这里使用的是负采样的方式，因此这部分的loss是：

![](https://upload-images.jianshu.io/upload_images/4155986-f4cd6af5e3ed0fb5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这一块介绍的比较简略，相信大家对于Skip-Gram都比较熟悉了，如果有不熟悉的同学，可以翻看word2vec相关的资料。

## 2.5 离线训练过程

离线训练过程如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-3c09638f88dd4eb6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

训练目标是使如下的联合loss最小化：

![](https://upload-images.jianshu.io/upload_images/4155986-1ebbac9aa1ca0084.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

由于主要的目标是提升点击率预估的效果，因此验证模型效果主要看一下在验证集上的AUC。

## 2.6 在线预测过程

在线预测过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-97553aaf662db60f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 3、实验结果

本文使用DeepMCP模型与LR、FM、DeepFM等模型进行了效果对比，在两个数据集上的AUC和Logloss表现如下：

![](https://upload-images.jianshu.io/upload_images/4155986-87654053c7059e80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 4、总结

本文提出的这个模型结构还是具有一定借鉴意义的，在传统的点击率预估中，一般会分召回和精排两个阶段，召回阶段通常使用的是协同过滤、双塔模型（一边计算item embedding，一边计算user embedding）。本文提出的模型感觉将召回阶段和精排阶段用到的方法进行了有效的融合，提升了点击率预估的效果。



# 推荐系统遇上深度学习(五十七)-[阿里]如何精确推荐一屏物品？


![](https://upload-images.jianshu.io/upload_images/4155986-d826c8b4ad59ec32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

今天介绍的论文题目是：《Exact-K Recommendation via Maximal Clique Optimization》

论文下载地址为：https://arxiv.org/pdf/1905.07089.pdf

之前介绍的推荐模型，大都是Top-K推荐的，也就是说，我们首先会对每个物品的CTR等进行预估，然后进行排序，将排序结果的前K个推荐给用户。这么做比较简单，但是忽略了推荐物品之间的内在联系。今天给大家分享的论文是阿里在KDD2019发表的论文，它能够综合考虑生成一个包含k个item的最优化集合，一起来了解一下吧。

# 1、背景

在许多推荐场景中，我们都需要一次性推荐一屏(论文中用到的词是card，这里我们暂且翻译为屏)的物品给用户，如下图：

![](https://upload-images.jianshu.io/upload_images/4155986-0e179b34b7573e78.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

文中将这种场景称之为exact-K recommendation问题，这种问题的首要目标是提升这一屏被点击或者满足目标用户需求的概率。同时，同一屏中的物品往往要满足一定的限制，比如推荐物品之间需要具有一定的多样性。

相比于传统的top-K推荐问题，exact-K推荐可以被视作一种多目标优化问题。在第二节中，我们一起来看看，阿里是如何做exact-K推荐的。

# 2、模型介绍

## 2.1 问题定义

对于给定的包含N个物品的候选集合S={s<sub>i</sub>}，我们的目标是从中选择K个物品集合A={a<sub>i</sub>}，并将这K个物品作为一屏推荐给用户。

这里，我们把A满足会被用户u点击或者满足用户u需求的概率定义为P(A,r=1|S,u)，同时，A中的物品两两之间有时需要满足一定的条件限制，定义为：

![](https://upload-images.jianshu.io/upload_images/4155986-9238cb3709265988.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

c<sub>k</sub>可以理解为两个物品之间的某种限制，如果满足限制，则c<sub>k</sub>=1，如果不满足限制，则c<sub>k</sub>=0。当然，物品之间有时也不需要条件限制，此时C=Ø。

这里的条件限制可能比较难理解，通过文中实验部分的数据集介绍给出一个例子。假设我们希望推荐的一屏结果中，两两物品之间的相关性没有那么高，也就是说多样性尽量多一些，此时我们的限制C定义为：

![](https://upload-images.jianshu.io/upload_images/4155986-6423ba49970adc9b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中的NED代表两个物品的名称之间的归一化编辑距离（normalized edit distance）。NED的计算方法就是编辑距离除以两个标题长度的较大值：

![](https://upload-images.jianshu.io/upload_images/4155986-a39ddb576972b965.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

回到正题，我们刚才描述的问题可以形式化表示为下面的组合优化问题：

![](https://upload-images.jianshu.io/upload_images/4155986-07b86b560944e5fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

从图论的角度，可以重新理解一下我们刚才的问题。首先，把S中包含的N个物品作为图中的N个节点，节点n<sub>i</sub>代表物品s<sub>i</sub>。如果物品之间的限制条件为空即C=Ø时，图中两两物品之间的都有边相连，如果C不为Ø时，只有满足了条件c<sub>k</sub>的物品之间才有边相连。既然要求推荐的K个物品两两之间都要满足条件c<sub>k</sub>，因此问题变为了图中一个非常经典的问题，即在图中找到一个K个节点的完全子图(完全子图即两两节点之间都有边的子图)：

![](https://upload-images.jianshu.io/upload_images/4155986-ce325e2cd0576e33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.2 朴素节点权重估计方法

这里首先介绍一种Base的方法，过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-829d63cd9a7ed607.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

过程表述如下：
1）对于给定的用户u和候选集合S，首先构造一张无向图；
2）计算图中每个节点的点击率CTR；
3）基于贪心的思路，从当前的候选集合中选择点击率最高的一个节点，加入到推荐结果集A中，并把至少与A中一个物品不相连的物品从当前的候选集中去掉；
4）重复第3步直到得到包含K个物品的推荐结果集合A。

这样做的缺点时我们无法得到一个最优解，仅能得到次优解。同时，点击率预估是单独针对一个物品来计算的，而且K个物品之间的组合关系也没有很好的考虑。因此，我们在下一节中将介绍本文提出的基于神经网络的方法。

## 2.3 Graph Attention Networks

本文提出的方法称为Graph Attention Networks，简称为GAttN，整体的框架如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-602c0ac5668a4659.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

整体的框架是一个Encoder-Decoder，但是Encoder和Decoder的设计包含一些业务思考。

**2.3.1 Input**

对于给定的图，图中每个节点n<sub>i</sub>对应的物品s<sub>i</sub>的特征记作x<sub>s<sub>i</sub></sub>，用户u的特征记作x<sub>u</sub>。因此Encoder的每个阶段的输入x<sub>i</sub>计算如下：

![](https://upload-images.jianshu.io/upload_images/4155986-42dd974513ce18fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**2.3.2 Encoder**

传统的Encoder往往选择循环神经网络，但这里顺序是没有意义的，因为输入的各个物品之间是无序的。尽管各个物品之间无序，但它们之间的相互影响还是需要考虑的。所以，这里的Encoder选择的是Transformer。

Transformer我们之前已经介绍过很多次了，这里不再赘述，如果感兴趣的同学可以参考文章：https://www.jianshu.com/p/2b0a5541a17c

Encoder使用多层的block，最后一层L层的输出为：

![](https://upload-images.jianshu.io/upload_images/4155986-e3cc317cad880d23.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**2.3.3 Decoder**

对于Decoder来说，要输出K个物品集合A，代表图中的一个包含K个节点的完全子图。这里使用的是循环神经网络，输出的集合是A的概率计算方式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-231de5e62eca084c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里f(S,u;θ<sub>e</sub>)代表的是encoder，θ<sub>d</sub>代表的是decoder的参数。得到输出是集合A的概率可以表示为得到A中每个物品的概率的乘积。

进一步，由于是循环神经网络，在得到a<sub>i</sub>时，输入包含两部分，一个是上一个阶段的隐藏层状态d<sub>i-1</sub>，另一个是上一阶段的输出a<sub>i-1</sub>，因此可以得到下面的式子：

![](https://upload-images.jianshu.io/upload_images/4155986-1965ee2b908b004d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中：

![](https://upload-images.jianshu.io/upload_images/4155986-482d99fde5d6db99.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来，需要介绍的是，在得到Decoder的隐藏层状态d<sub>t</sub>之后，如何得到当前选择的物品a<sub>t</sub>。其过程在图中表示的比较清楚：

![](https://upload-images.jianshu.io/upload_images/4155986-cf21157ac619bac8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

首先，这里借鉴pointer-network的的做法，使用一个attention机制，先让decoder回顾一遍所有的encoder输出，并得到每个输出的权重，作为当前选择的一个依据：

![](https://upload-images.jianshu.io/upload_images/4155986-560f5a214a6b93ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来，我们要计算选择每个物品的概率，首先这里需要注意的一点是，Encoder每个阶段的输出组合起来，应该是图中的一个完全子图，因此，要确保当前选择的物品能够与之前选择的物品在同一个完全子图中，如果不能满足这个条件，需要通过添加mask的方式，确保其不会被选择到：

![](https://upload-images.jianshu.io/upload_images/4155986-d5f165b2afee55b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-f9d0103cb510c51f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

介绍完模型结构，接下来咱们介绍模型如何训练。

# 3、模型训练

## 3.1 整体思路

先说说整体的思路，首先我们的优化目标是整个一屏的推荐结果集合A的点击概率最高，但按照监督学习的思路的话，由于Decoder阶段使用的是RNN的结构，我们只能计算每个阶段的交叉熵损失或者平方损失，因此网络的优化目标和实际想要的目标是存在一定的gap的。因此，考虑通过强化学习中policy-gradient的思路。但是直接使用policy-gradient的方法，其训练周期是十分长的，前面的探索效率可能无法得到有效的保证。

综上所述，本文中采取的思路是，首先通过监督学习的方式对网络参数进行一定的预训练，然后再通过策略梯度的方式进一步修正网络参数。使用监督学习文中称作Learning from Demonstrations，使用强化学习称作Learning from Rewards.

## 3.2 Learning from Demonstrations

我们可以从历史日志中收集一批真实的训练数据：

![](https://upload-images.jianshu.io/upload_images/4155986-b7afb30490ba6595.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过交叉熵损失训练模型：

![](https://upload-images.jianshu.io/upload_images/4155986-87427419fdf1ccda.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

使用上面的式子存在的一个问题就是，训练阶段时，Decoder输入的是真实的物品，而在预测时，Decoder输入的是上一阶段输出的物品，这就容易导致一步错步步错的问题，因此文中说在训练阶段时，Decoder输入也直接使用上一阶段输出的物品。因此损失变为：

![](https://upload-images.jianshu.io/upload_images/4155986-2d324892ee1f702b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

两种方式还是都训练看看吧，个人经验来看也许第一种会好一些。

## 3.3 Learning from Rewards

这里，把f(S,u;θ<sub>e</sub>)作为状态state的话，decoder阶段输出的组合A可以看作动作action，我们需要一个仿真环境来计算state和action对应的reward，直接使用历史数据的话显然是不够的，因为大量的（state，action）组合没有出现过。因此借鉴反向强化学习（Inverse Reinforcement Learning）的思路，来训练一个奖励估计器(Reward Estimator)。该估计器也好训练，即基于历史数据来训练一个二分类模型（这里使用的是PNN模型），损失是logloss：

![](https://upload-images.jianshu.io/upload_images/4155986-ccdbe45163ee8edb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

有了奖励估计器，就可以通过策略梯度方法训练网络：

![](https://upload-images.jianshu.io/upload_images/4155986-b0667082459d5267.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而奖励需要归一化到-1到1之间：

![](https://upload-images.jianshu.io/upload_images/4155986-5885d1b0a8359800.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里文中还提到了一点是，由于训练二分类模型时正负样本十分不均衡，正样本偏少，这样也会导致我们很难收到正向的reward，因此论文中借鉴了爬山法的思想，每次保存5个结果，并从这五个结果中选择能获得最大奖励的一个结果进行模型训练。

## 3.4 Combination

结合两种训练方式，模型的最终loss为：

![](https://upload-images.jianshu.io/upload_images/4155986-6f3939fddf8dbf29.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里的参数a在[0,1]之间，并且是随着训练的进程进行调整的。训练初期，将a设置为一个较大的数，使得监督学习占据比较大的权重，便于模型的快速收敛，随后a慢慢变小，逐渐向强化学习方式偏移，对参数进行调整，这样往往可以得到一个比较不错的结果。

# 4、总结

这里，实验结果部分就不介绍了，整个论文的思路还是比较完整的。可以借鉴的有以下几点吧（个人理解）：
1）为整屏推荐提供了一种解决思路。
2）训练过程整合了监督学习和强化学习的思路，相当于使用监督学习进行预训练，再使用强化学习进行参数调整。使用监督学习加速训练过程，使用强化学习使得训练和测试目标保持一致。
3）模型选择结合业务思考，比如encoder的选择，选择Transformer是因为输入之间没有顺序关系，但相互之间还存在一定的影响。
4）为了提升推荐结果的多样性（或者其他目标），将其转换为一个求完全子图的问题，并通过在decoder阶段加入mask的方式对输出进行限制。

感觉这篇文章还是有一定难度的，自己可能有些地方也总结的不太到位，对论文感兴趣的小伙伴可以看下原文，与小编一起讨论！



# 推荐系统遇上深度学习(五十八)-基于“翻译”的序列推荐方法


![](https://upload-images.jianshu.io/upload_images/4155986-9900472d190ef7c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文的题目是《Translation-based Recommendation》
论文下载地址是：https://arxiv.org/abs/1707.02410

# 1、背景

在推荐系统中，建模和预测用户和物品、物品和物品之间的关系是十分重要的。而在序列推荐中，为了预测用户下一个可能交互的物品，需要建模三方的关系。这三方分别是用户u、用户最近交互的物品i（或者一系列物品）、下一个要交互的物品j。

传统的方法大多仅仅建模两方的关系，如矩阵分解模型仅仅建模用户和物品的交互关系，而马尔可夫链的方法仅仅建模用户交互序列中物品的关系。

在本文中，我们提出了一个基于“翻译”（这里加引号是不太确定Translation-based是否应该解释成基于“翻译”的模型，只是暂时这么解释）的推荐模型来同时建模三方的关系，一起来学习一下。

# 2、模型介绍

## 2.1 问题定义

本文中用到的一些符号如下：

![](https://upload-images.jianshu.io/upload_images/4155986-a7ee670f754976bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

公式打起来不方便，所以直接在图上进行了解释，嘻嘻。

## 2.2 模型结构

模型的基本思想很简单，如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-3652327e12948b7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其基本的思路就是用户对应的向量和用户上一个交互过的物品向量之和，要和用户下一个要交互的物品向量在距离上相近。

![](https://upload-images.jianshu.io/upload_images/4155986-885322a3927afdc3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里物品向量用γ<sub>i</sub>表示，用户向量用T<sub>u</sub>表示，而T<sub>u</sub>可以被分解为两部分：

![](https://upload-images.jianshu.io/upload_images/4155986-53bacb790cf07ab2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这么分解乍一看和直接学习一个t<sub>u</sub>没有区别，但实际推荐的场景中，往往存在数据稀疏以及冷启动的问题，因此学习一个全局的向量t，可以一定程度上解决冷启动的问题。对于新来的用户，将t<sub>u</sub>被设置成零向量即可，即T<sub>u</sub> = t。

接下来，我们考虑一个问题，如何处理热门物品？如果一个物品十分热门，在训练集中出现的次数非常多，那么会导致热门物品对应的向量与许多用户+物品向量的距离非常近，导致推荐时热门物品出现的次数非常多，一定程度上降低了推荐结果的多样性，因此本文的做法是对热门物品进行一定的惩罚：

![](https://upload-images.jianshu.io/upload_images/4155986-3635605ee1270b25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

当用户u上一个交互的物品是i时，下一个交互的物品是j的概率应该正比于距离的相反数（即距离越小，推荐的可能性越大），除此之外，对每一个带推荐物品，这里还加入了一个常数β<sub>j</sub>。并通过β<sub>j</sub>对热门物品进行一定的惩罚，如越热门的物品β<sub>j</sub>越小，这样的话，如果对物品j和j'的距离相同，但j物品相较于j'更加热门，此时β<sub>j</sub> 会小于β<sub>j'</sub>，因此更倾向于推荐j'，从而提升推荐结果的多样性。

## 2.3 模型训练

模型的整体思路比较简单，在训练时使用pair-wise的方法：

![](https://upload-images.jianshu.io/upload_images/4155986-6cdfd82b6888f776.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中j是真实的下一个交互的物品，j'是除j之外的任意一个物品。

## 2.4 模型预测

在预测阶段，依据距离度量，找到距离最近的物品进行推荐。但到目前为止，我们还没有介绍距离度量的方式，下一节来看一下。

## 2.5 距离度量

这里文中说距离度量可以用L1的方法，也可以使用L2的方法，二者的计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-7c5f38485cbbead6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

但从实验结果来看，L2距离是更好的选择。

# 3、总结

本文略过了实验结果部分，感兴趣的同学可以看一下原文。本节咱们对文中的思路做一个简答的总结：

1）文中使用距离度量的方式，将用户、用户交互过的物品、待推荐物品通过一个公式同时进行考虑。
2）文中提出的方式可以很容易处理长度较长的用户交互序列，因为在使用时仅仅考虑上一个交互的物品。
3）成功将度量学习(Metric Learning)和知识图谱补全(knowledge-graph completion)的思路引入到了推荐系统中， 并取得了不错的效果。简单说一下知识图谱补全，其基本的思想也是将图谱中的实体、关系转换成向量表示，并基于已有的三元组关系去预测未知的实体之间的关系，可以表示成如下的式子：

![](https://upload-images.jianshu.io/upload_images/4155986-1120dba43a4ba986.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看出与本文的思路十分类似，用户的向量T<sub>u</sub>可以近似表示成一种relation。
4）基于本文的思路，又衍生出了其他的论文，如将其与FM进行融合的方法，我们将在下一篇文章中进行介绍，小小期待一下吧。



# 推荐系统遇上深度学习(五十九)-FM家族的新朋友FAT-DeepFFM


![](https://upload-images.jianshu.io/upload_images/4155986-dc6202b6127b3cb5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

今天给大家介绍的文章标题是：《FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine》
文章下载地址是：https://arxiv.org/abs/1905.06336

从本系列的第一篇开始，咱们已经陆续介绍过FM模型、FFM模型、DeepFM模型、NFM模型和AFM模型。今天给大家介绍的是FM家族中的另一个新朋友FAT-DeepFFM（全称是Field Attentive Deep Field- aware Factorization Machine），是由新浪微博的张俊林老师提出的哟，一起来学习下。

# 1、背景

点击率预估是计算广告以及推荐系统中非常重要的工作，学者们也提出了许多有效的模型来做CTR预估任务。如LR、树模型、贝叶斯模型、FM模型、FFM模型，以及深度学习模型如DeepFM、Wide & Deep模型等等。

同时，CTR模型中也经常借鉴其他领域的一些常用方法，如计算机视觉和自然语言处理中常用的方法，最为常见的是Attention机制。使用Attention机制可以从众多的特征中选择出比较重要的特征，并过滤掉一些无关特征。将注意力机制和深度学习CTR预估模型相结合，如AFM模型已经被学者们提出，AFM模型结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-5b337dd109d82093.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/728)

可以看到，上面的AFM模型，是在特征进行交叉之后，再对交叉特征进行权重计算，但本文认为，在特征进行交叉之前，对特征的重要性进行一个计算也十分重要。当特征为n个时，交叉后计算重要性的权重个数为n的平方，但是交叉前计算特征重要性的话，只需要计算n个权重。这么做的话在特征比较多的时候，对计算资源的节省是十分明显的。

好了，接下来，咱们就一步步来看看俊林老师提出的模型吧。

# 2、DeepFFM模型

在介绍FAT-DeepFFM之前，先介绍DeepFFM模型长什么样子，因为这个模型对大家来说应该也相当陌生。

## 2.1 FM模型

FM模型对每一个特征赋予一个k维的向量，并通过对应向量的内积来当作特征交叉的权重，其预估公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-5c8499ccada1746b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.2 FFM模型

相较于FM模型，FFM模型提出了Field的概念，假设有n个域的话，每一个特征都对应了n-1个k维的向量，其预估公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-a3cac05b64654296.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.3 DeepFFM模型

FM和深度神经网络相结合，我们已经有了DeepFM模型，很自然的，FFM和深度神经网络相结合，就有了DeepFFM模型，其模型结构如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-abf4addcfc63f0bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如图所示，我们的特征首先被转换成一堆one-hot encoding，每一个one-hot encoding可以看作一个field，如性别、周几等等。

还是想说一下本文的特征和field定义，比如有两个域，性别和周几，那么特征数量是2+7=9，当然你也可以认为是3 + 8=11，两个域各加一个未知选项嘛。

接下来在Embedding matrix layer，每一个特征将会得到一个对应的Embedding Matrix，简称EM，如对于第I个特征：

![](https://upload-images.jianshu.io/upload_images/4155986-48a34efcfeaa80fd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

假设有n个域，每个特征对应的EM的大小为k * n，整个EM层的大小为k * n * n （这里每个特征对应n个k维向量，而非n-1个，但实际参与计算和更新的只有n-1个）。

接下来，有两种方式得到DNN部分的输入，分别是计算内积和哈达玛积：

![](https://upload-images.jianshu.io/upload_images/4155986-aa6a9f5d2b6b3375.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

哈达玛积的计算公式如下（文中这里感觉写错了，圆圈中间应该是乘号而非加号）：

![](https://upload-images.jianshu.io/upload_images/4155986-ec61d34b6fef78a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，如果使用内积的话，输入DNN的维度是n(n-1)/2的，如果使用哈达玛积的话，输入DNN的维度应该是kn(n-1)/2。随后经过多层神经网络：

![](https://upload-images.jianshu.io/upload_images/4155986-b33bea4a6c4666bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而最终DeepFFM的输出为：

![](https://upload-images.jianshu.io/upload_images/4155986-a43c105bab7f5ffa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

至此DeepFFM就介绍完了，和DeepFM有点不一样，DeepFM保留了FM中的一次项、二次项（特征交叉项），但DeepFFM中，只计算了一次项，二次项没有保留，也许是出于计算时间的考虑吧。

# 3、FAT-DeepFFM模型

好了，接下来介绍FAT-DeepFFM模型，与大多数模型借鉴的自然语言处理中的注意力机制不同，这里引入的注意力机制来源于图像领域的SENet，一起来看一下。

FAT-DeepFFM模型的整体的结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-d944086ff10df53e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而注意力机制发挥作用的部分是：

![](https://upload-images.jianshu.io/upload_images/4155986-f18d4569282d492e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

论文中提出的Attention机制称为CENet Field Attention，全称为Compose-Excitation network (CENet) attention mechanism。接下来，咱们就来一步步解读这个Attention过程。

## 3.1 CENet Field Attention

这里Attention的过程分为两个阶段，分别称作Compose阶段和Excitation阶段。

**Compose阶段**

在Compose阶段，需要把每一个向量压缩成一维的值，每一个特征对应的Embedding Matrix是k * n，压缩之后变为一个n维的向量，如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-048e7f582200296e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

假设当前是第i个特征，对应的特征矩阵是EM<sub>i</sub>，EM<sub>i</sub>中的列向量分别是v<sub>i1</sub>,v<sub>i2</sub>，...,v<sub>in</sub>其压缩后对应的向量是z<sub>i</sub>。

对于SENet来说，直接对每一列使用max pooling来得到值，具体的，对于z<sub>i</sub>中的第f个值，通过下面的式子得到：

![](https://upload-images.jianshu.io/upload_images/4155986-6babdb5fa73a5270.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在本文中，对这种方式进行了一定的修改，使用1维卷积：

![](https://upload-images.jianshu.io/upload_images/4155986-286bd6e56f7e0784.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里的卷积核是1 \* 1的。有关1维卷积以及1\*1卷积核，这里我一开始理解有误，认为论文里写的是错误的，不过经指正这里应该是没错的，感兴趣的小伙伴可以看下1维卷积、1\*1卷积以及1\*1卷积和全连接的区别。待我总结归来，一定将经验分享给大家。

**Excitation阶段**

经过Compose阶段，每个特征对应的Embedding Matrix，都得到了一个对应的n维压缩向量，例如特征i对应的n维压缩向量计作DV<sub>i</sub>，那么在Excitation阶段，我们首先对DV进行横向拼接：

![](https://upload-images.jianshu.io/upload_images/4155986-d7b861101bd34b57.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里D是n * n维的向量，接下来将D输入到两层全连接网络中：

![](https://upload-images.jianshu.io/upload_images/4155986-262fbb45c2a0b34e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

从上图可以看出，经过全连接网络之后输出的S仍然是n * n维的向量，S便是我们想要得到的attention score。

利用attention score就可以对我们Embedding Matrix进行加权了，例如第i个特征：

![](https://upload-images.jianshu.io/upload_images/4155986-60605a2cc10b63e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

到了这一步，剩下的就跟DeepFFM里面所讲的一致啦，这里就不细讲啦。

# 4、实验及总结

论文在两个数据集上进行了实验，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-72a5b54eddf065c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以发现，FAT-DeepFFM的效果好于其他对比模型，同时，使用哈达玛积的时候效果会比使用内积效果更好。

这篇论文应该放出来有一段时间了，俊林老师也在知乎上介绍了这个思路，今天看了一下其主要创新点还是在于attention的计算吧，借鉴了图像领域的思路，还是值得尝试一下的。



# 推荐系统遇上深度学习(六十)-FM家族的新朋友之TransFM

![](https://upload-images.jianshu.io/upload_images/4155986-c793bfe88d300871.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/430)


![](https://upload-images.jianshu.io/upload_images/4155986-4e40a71bbd08832d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文的题目为《Translation-based Factorization Machines for Sequential Recommendation》

论文下载地址为：https://cseweb.ucsd.edu/~jmcauley/

在本系列的第五十八篇文章中，我们介绍了一种基于“翻译”（Translation-based，本文仍然延续基于“翻译”这种解释方法）的序列推荐方法TransRec，本篇咱们一起来看看这种方法与FM相结合，会擦出什么样的火花。

# 1、背景
这里，首先简单回顾一下TransRec的内容，其基本的思路就是用户对应的向量和用户上一个交互过的物品向量之和，要和用户下一个要交互的物品向量在距离上相近。

![](https://upload-images.jianshu.io/upload_images/4155986-3635605ee1270b25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里的距离计算一般选择平方距离。上面的思路借鉴了度量学习（metric learning）和知识图谱补全（knowledge-graph completion）的思路，取得了不错的效果。

而FM模型是推荐系统领域非常重要的模型，其对每一个特征赋予一个k维的向量，并通过对应向量的内积来当作特征交叉的权重，其预估公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-5c8499ccada1746b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

那么，将FM中基于内积来计算交叉特征权重的方法，改为距离计算方法，便得到了本文中提出的Translation-based Factorization Machines，即TransFM。

# 2、TransFM

## 2.1 问题描述

下面的表格是对一些符号的定义：

![](https://upload-images.jianshu.io/upload_images/4155986-24a3ae17a3a5c12a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

x是特征向量，该向量包含四个部分，分别是用户特征、用户前一个交互的物品i、用户下一个交互的物品j，还有一部分的上下文特征。总共的特征长度是n（one-hot之后的长度，而不是field的个数），这里给每个特征两个对应的k维向量，一个我们称作embedding vector，这个和FM是一致的，另一个称作translation vector，分别记作v<sub>i</sub> 和 v'<sub>i</sub>。

## 2.2 TransFM模型及分析

TransFM模型示意图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-1437b12aaf31ab2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在融合基于“翻译”的思想后，TransFM的点击率计算公式变为：

![](https://upload-images.jianshu.io/upload_images/4155986-706e1ffc3100dede.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中， d<sup>2</sup>是平方距离计算公式：

![](https://upload-images.jianshu.io/upload_images/4155986-a03694f0ecfcf0f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

使用距离计算公式的一个好处是如果特征组(a,b)和(b,c)的距离很近，那么特征组(a,c)的距离也会很近，因为三角形两边之和一定大于第三边的长度。

下图展示了几种不同的方法的可视化展示：

![](https://upload-images.jianshu.io/upload_images/4155986-a6cab7a85c619e33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-0805b263ca93920e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

PRME的全称是Personalized Ranking Metric Embedding ，其核心是计算用户embedding和物品embedding的距离；FM是通过计算特征对应的向量的内积来计算二者相关性的；TransRec和TransFM也是两种基于距离的学习方法。

看到这里你可能会和我有一样的疑问，这里为什么要对一个特征搞两个向量？每一个特征对应一个embedding vector，然后把内积计算改成距离计算不就好了么？按照这个思路，计算点击率的公式应该为：

![](https://upload-images.jianshu.io/upload_images/4155986-799551091b9a5a41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

文中作者在实验部分也对比了这么做和TransFM的效果，TransFM的效果是较优的。

## 2.3 模型计算复杂度

我们都知道，FM是可以通过化简来极大降低计算的时间复杂度的，同样的TransFM也可以进行化简，一起来看一下。

首先，距离公式可以改写为：

![](https://upload-images.jianshu.io/upload_images/4155986-ef6f1b719daba4cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

所以，交互部分可以进一步化简：

![](https://upload-images.jianshu.io/upload_images/4155986-e490447a9416d833.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

咱们还是来拆解一下上面的步骤：

![](https://upload-images.jianshu.io/upload_images/4155986-eb41abc8a36e6556.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-eb720ea89b912f71.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

别看第一项可以细分为六个部分，每一个部分都是可以继续化简的，比如：

![](https://upload-images.jianshu.io/upload_images/4155986-3e5d24943291ebe7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样，假设有n个feature，向量长度为k，那么时间复杂度是O(nk)，而非O(n<sup>2</sup>k)

## 2.4 模型训练

模型的训练采用pair-wise的方式，在已知用户u上一个交互过的物品i的情况下，我们知道下一个用户交互的物品j，那么除去j之外的所有物品都可以当作负样本，优化目标如下：

![](https://upload-images.jianshu.io/upload_images/4155986-72a745686d016005.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 3、总结

本文将Translation-based的思想和FM相结合，提出了TransFM方法，在几个数据集上的效果均好于FM模型和TransRec模型。



# 推荐系统遇上深度学习(六十一)-[阿里]使用Bert来进行序列推荐


![](https://upload-images.jianshu.io/upload_images/4155986-57facd6387f16b1c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文题目是《BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer》
论文下载地址为：https://arxiv.org/abs/1904.06690

将Transformer运用到推荐系统中，前面也介绍过许多篇相关的论文了，如阿里的DSIN、BST等等，他们都使用Transformer的Encoder部分的网络结构作为模型中的一部分进行使用。同时，在自然语言处理领域，同样使用Transformer的Encoder部分的预训练模型Bert取得了巨大的成功，其一些训练的思路能否同样应用到推荐系统中呢？答案是肯定的，本篇介绍的文章就是如此，一起来了解一下。

# 1、背景

在推荐系统中，精确捕捉用户的兴趣，是比较关键的。而用户的兴趣是随着历史行为的变化而不断变化的，为了捕捉这种兴趣的变化，一些序列推荐算法被提出。如使用马尔可夫链，使用RNN模型等等。

无论是马尔可夫模型还是RNN模型，都是使用用户从前到后的历史行为序列信息，这种单向的结构有时对历史行为序列所能带来的作用是有一定限制的；同时，这种顺序性的假设有时候在实际生活中并不适用，如下图中，三种口红的点击顺序，对于最后的推荐结果影响并不是很大：

![](https://upload-images.jianshu.io/upload_images/4155986-676f95a977cde5cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因此，本文认为双向模型对于序列推荐来说，更加有效。由于用户的行为序列很像是文本序列，而Bert模型算是当前自然语言处理领域数一数二的模型，其使用Transformer的Encoder进行预训练任务，能够有效利用双向信息，因此本文考虑将Bert用于推荐任务。接下来，咱们就来介绍BERT4Rec模型吧。

# 2、BERT4Rec模型介绍

使用BERT进行序列化推荐，其整体的模型结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-e67074882eab46eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.1 问题定义

在序列化推荐中，我们有如下的符号定义

| 结构             |                             描述                             |
| ---------------- | :----------------------------------------------------------: |
| 用户集合         | ![](https://upload-images.jianshu.io/upload_images/4155986-f4f5123b89926328.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) |
| 物品集合         | ![](https://upload-images.jianshu.io/upload_images/4155986-7bce9ff2abc4563d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) |
| 用户历史行为序列 | ![](https://upload-images.jianshu.io/upload_images/4155986-54105efac87feb4e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) |

我们的目标是预测下一时刻用户与每个候选物品交互的概率：

![](https://upload-images.jianshu.io/upload_images/4155986-39bbbaefd9ff5cb7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.2 Embedding Layer

模型的输入主要是用户的历史交互序列，对交互序列中的每一个物品i，其Embedding包含两部分，一部分是物品的Embedding，用v<sub>i</sub>表示（整个Embedding矩阵用E表示，不仅用在输入层，还用在输出层），另一部分是位置信息的Embedding，用p<sub>i</sub>表示。这里的p<sub>i</sub>是可学习的，而不是像最开始提出的Transformer一样是固定的。

另一点需要指出的是，输入并不是使用用户所有的历史行为信息，而是使用最近N个行为。因为用户的行为序列长度差别很大，如果不加限制，可能导致模型过大，性能降低。

## 2.3 Transformer Layer

Transformer Layer的结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-1ac1b7176f0aa8d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里具体的Transformer的细节咱就不讲了，之前我写过一篇详细剖析整个过程的文章，感兴趣的同学可以查看：https://www.jianshu.com/p/2b0a5541a17c

对于模型框架中的第l层Transformer Layer，输入为H<sup>l</sup>,首先是Multi-Head Self-Attention过程：

![](https://upload-images.jianshu.io/upload_images/4155986-875b3c83441f507e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-3e52f44277de9b18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其次是DropOut和Add & Norm过程，这里的Add操作和ResNet类似，使得模型的层数可以非常深，而Norm是我们熟悉的BN操作，其计算方式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-1348799f52e87612.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

之后是Position-wise Feed-Forward Network，Position-wise的意思是说，每个位置上的输入分别输入到前向神经网络中，计算方式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-f192f6672b593505.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里采用的激活函数是 Gaussian Error Linear Unit (GELU) ，而非RELU，这个激活函数还是第一次见，其出自论文https://arxiv.org/abs/1606.08415，

GELU的计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-f258693b98e0ebed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

原文中和本文中均使用N(0,1)。GELU和Relu以及ELU的对比图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-110a9a510e6b09f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

Gelu在relu的基础上加入了统计的特性，在论文中提到的好几个深度学习任务中都取得了更好的实验结果。

最后还是一个Dropout和Add & Norm过程。

## 2.4 Output Layer

在经过L层的Transformer Layer之后，得到的输出为H<sup>L</sup>，最后经过两层全连接网络得到最终的输出：

![](https://upload-images.jianshu.io/upload_images/4155986-a0366cee6536ecea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中，最后一层的参数E，是物品的Embedding矩阵，和输入层是一样的矩阵。

## 2.5 模型训练和预测

首先再来仔细看一下BERT4Rec的结构，以及对比一下另外两个序列推荐模型：

![](https://upload-images.jianshu.io/upload_images/4155986-af42f868f2ffb61e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们的目的是预测用户下一个要交互的物品v<sub>t+1</sub>，对于传统的序列推荐模型，如上图中的RNN模型，输入是[v<sub>1</sub>,v<sub>2</sub>,...,v<sub>t</sub>]，转换为对应的输出为[[v<sub>2</sub>,v<sub>3</sub>,...,v<sub>t+1</sub>]，那么我们自然可以拿最后一个时刻的输出来作为物品进行推荐。

而在BERT4Rec中，并没有这样的转换过程，输入[v<sub>1</sub>,v<sub>2</sub>,...,v<sub>t-1</sub>]，其输出只不过是包含了上下文信息的向量[h<sub>1</sub>,h<sub>2</sub>,...,h<sub>t-1</sub>]罢了。在上面的图片中，假设我们要预测用户t时刻的交互物品v<sub>t</sub>，如果直接把v<sub>t</sub>作为输入，那么其余每个物品在Transformer Layer中看到目标物品v<sub>t</sub>的信息，这样就造成了一定程度的信息泄漏。因此图中把对应位置的输入变成了[mask]标记。

训练和预测都可以采用上图中的方式，在预测下一个物品时，在输入序列的最后添加一个[mask]标记，共同作为输入。但是为了提升模型的泛化能力，让模型训练到更多的东西，同时也能够创造更多的样本，在训练阶段，借鉴了BERT中的Masked Language Model的训练方式，随机的把输入序列的一部分盖住（即变为[mask]标记），让模型来预测这部分盖住地方对应的物品：

![](https://upload-images.jianshu.io/upload_images/4155986-a69b4a73c739bff1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

采用这种训练方式，最终的损失函数为：

![](https://upload-images.jianshu.io/upload_images/4155986-59703532ad159138.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-f35e09de3c3a37a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 3、实验结果

简单看一下实验结果吧。

文章首先对比了模型和一些Base模型在4个数据集上的表现：

![](https://upload-images.jianshu.io/upload_images/4155986-caf30190974edd11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到BERT4Rec模型相较于Base模型，其性能都有较大提升。

接下来，是参数的对比，首先是Embedding的长度d：

![](https://upload-images.jianshu.io/upload_images/4155986-519192e760df6067.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

Embedding的长度越长，模型的效果更好。随后是训练时盖住物品的比例：

![](https://upload-images.jianshu.io/upload_images/4155986-aaa50fba98e9e4d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于不同的数据集来说，最佳比例并不相同。然后是序列的最大长度N：

![](https://upload-images.jianshu.io/upload_images/4155986-ad0e126e24e25dd0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

同样，不同的训练集，最佳的序列长度也不相同。最后，是对模型结构的一些对比试验，主要有是否使用PE(positional embedding)，是否使用PFFN(position-wise feed-forward network)，是否使用LN(layer normalization)，是否使用RC（即Add操作，residual connection)，是否使用Dropout，以及Transformer Layer的层数和Multi-head Attention中head的个数，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-f1afc2a6d7617bc8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 4、BERT4Rec VS BST

好了，啰嗦了这么多，最后再多说一点，咱们之前也介绍过一个使用Transformer的推荐模型BST(Behavior Sequence Transformer)，其结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-1418d5b13a902e80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对BST模型来说，需要输入一个target item，模型输出的是点击这个target item的概率；而对BERT4Rec模型来说，模型一次性输出所有候选物品的点击概率，因此在参数差不多的情况下，单从性能而非预测精度来说，BERT4Rec肯定是更好的。因此个人认为，BST用在精排阶段更加合适，而BERT4Rec可以用于召回阶段，也可用于精排阶段。



# 推荐系统遇上深度学习(六十二)-[阿里]电商推荐中的特殊特征蒸馏

![](https://upload-images.jianshu.io/upload_images/4155986-ccb9f88efb69df88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

今天介绍的论文是：《Privileged Features Distillation for E-Commerce Recommendations》
论文下载地址为：https://arxiv.org/abs/1907.05171?context=cs.IR

说说题目吧，先讲讲蒸馏（Distillation）的概念，我们知道模型最终都要应用于线上，如果太过复杂的模型会导致性能无法保证，往往会应用一个比较简单的模型。但简单的模型有时难以保证预测精度，因此一种做法是训练一个复杂的模型作为老师来指导这个简单模型的训练。这种教师-学生的训练模式，便称为蒸馏。再讲讲Privileged Features，我们这里暂且翻译为特殊特征。好了，进入正文吧。

# 1、背景

在淘宝的推荐系统中，整个推荐流程可以分为下面的三个阶段：

![](https://upload-images.jianshu.io/upload_images/4155986-16ca4444113b9c7e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

首先是候选集生成阶段(candidate generation)，接下来是粗排阶段(coarse-grained ranking)，最后是精排阶段(fine-grained ranking)。这里跟咱们之前接触的两阶段过程不太一样，接下来分别介绍各阶段的内容。

在候选集生成阶段，通过多路召回的方式得到候选集合，召回方式可能有协同过滤、DNN模型等等。

在粗排阶段，主要的任务是预估精排阶段返回的候选集中每个物品的点击率，然后选择最高的一些物品进入精排阶段。粗排阶段输入的特征主要有用户的行为特征（用户的历史点击／购买行为，通常通过RNN或者self-attention进行处理）、用户自身特征（如用户id、性别、年龄）、物品自身特征（如物品id、类别、品牌）。在粗排阶段，考虑到性能的关系，模型的复杂度受到了很大的限制，因此通常是用下面的双塔结构：

![](https://upload-images.jianshu.io/upload_images/4155986-8945348ec02b9c3c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

点击率计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-927fcf110a230ac3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中X<sup>u</sup>和X<sup>i</sup>代表用户和物品对应的向量，X<sup>u</sup>混合了用户本身特征和用户行为序列特征。W<sup>u</sup>和W<sup>i</sup>代表用户和物品侧的参数，而Φ代表从输入到输出的映射关系。在线上应用阶段，可以预先把每个物品的映射计算出来，作为词表进行保存，当一个请求到来时，只需要计算用户侧的映射即可。过程如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-f6d0a8a3319e1b4b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

由于性能的限制，在粗排阶段没有考虑用户-物品的一些交互特征，如用户过去24小时在同类别下物品的点击行为、用户在过去24小时在物品所在店铺内的点击行为。加入这些特征，如果放到用户侧，那么针对每个物品都需要计算一次用户侧的映射，如果放到物品侧，同样针对每个物品都需要计算一次物品侧的映射，这会大大加大计算复杂度。因此，这些交互特征对于粗排阶段的模型来说，通常在线上无法应用，我们就称为Privileged Features。

最后讲一下精排阶段，这一阶段我们不仅要预估CTR、还要预估CVR，因为电商领域的推荐的目标一般是提高GMV（CTR * CVR * Price，商品的Price是确定的，无需预估）。CVR的定义是用户从点击到购买的概率。那么对于用户购买来说，用户在商品详情页面停留的时间、对于评论的查看与否、是否会与商家进行交流会是一些比较有用的强特征。但是，这些特征在线上预估阶段是无法获取的，我们需要在给用户展示物品的时候就来预估CVR，所以对于CVR预估来说，用户在点击后进入到商品详情页的一些特征同样是Privileged Features。

使用这些Privileged Features，是可以提升模型的预测精度的。因此本文借鉴模型蒸馏的思想，让粗排阶段的CTR模型或者是精排阶段的CVR模型，都能够学习到一些Privileged Features的信息。下一节，咱们来具体学习一下。

# 2、特殊特征蒸馏(Privileged Features Distillation)

接下来，咱们以粗排阶段的CTR预估来讲一下本文中提出的蒸馏技术。

## 2.1 模型蒸馏 VS 特殊特征蒸馏

先来看一下模型蒸馏Model Distillation和特殊特征蒸馏Privileged Features Distillation的对比：

![](https://upload-images.jianshu.io/upload_images/4155986-754872383802704e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

二者的思路都是训练一个复杂的Teacher网络和一个简单的Student网络，并通过Teacher网络来在一定程度上指导Student网络的学习。对于模型蒸馏Model Distillation来说，两个网络的输入是相同的，只是Teacher网络的模型结构更加复杂；对于Privileged Features Distillation来说，两个网络的结构是相同的，只不过Teacher网络可以输入更多的Privileged Features。

## 2.2 Unified Distillation(UD)

如果只使用Privileged Features Distillation，Teacher网络和Student网络均使用双塔结构的话，这其实也对模型的能力在一定程度上进行了限制。因此实际应用中，融合Model Distillation和Privileged Features Distillation，便得到Unified Distillation。其结构示意图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b9c6032584e7cd05.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于Teacher网络，使用多层神经网络来进行学习，而对于Student网络，还是使用双塔结构。

## 2.3 模型训练

既然是用Teacher网络来指导Student网络的训练，那么常见的一种方式是，先训练好一个比较精确的Teacher网络，然后再训练Student网络。Student网络的损失函数如下：

![](https://upload-images.jianshu.io/upload_images/4155986-0ae3354f9a3f7618.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上面的损失函数被分为两部分，两部分都是计算交叉熵。其中X*代表Privileged Features。损失的第一部分是可以称为hard loss，其label是[0,1]或者[1,0]，第二部分可以称为soft loss或distillation loss，其label是Teacher网络的输出，如[0.8,0.2]（0.8的概率点击，0.2的概率不点击）。

但是，如果先训练Teacher网络，在阿里的实际场景中需要数天的时间。因此，一种做法是同时训练Teacher网络和Student网络，二者的损失函数变为：

![](https://upload-images.jianshu.io/upload_images/4155986-df47d2e83db10290.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这么做虽然能够带来训练速度的提升，但有时候的效果是比较差的。这主要是由于在训练的初期，Teacher网络的精度不够，给出的结果容易误导Student网络。因此通过对参数λ的控制来调整Teacher网络对于Student网络的影响。在初期，λ比较小，Teacher网络对于Student网络的影响较小，而随着训练的进行，逐步增加λ，让Student学习到更多的Teacher网络的信息。

论文里还提出了两点值得注意。首先是更新Teacher网络的时候，把distillation loss剔除，避免Student网络影响到teacher网络。第二点就是Teacher网络和Student共享特征的embedding，这样就极大减少了参数的数量。

# 3、实验结果

简单看一下实验结果，这里对比了模型蒸馏、特殊特征蒸馏以及混合方式下Teacher网络和Student网络的AUC，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-a898d84a3cf3156d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，混合方式下得到了最好的AUC。其他的一些实验结果大伙可以看下论文。



# 推荐系统遇上深度学习(六十三)-[阿里]大型推荐系统中的深度序列匹配模型SDM

![](https://upload-images.jianshu.io/upload_images/4155986-1c55f90931b53339.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

今天介绍的论文是：《SDM: Sequential Deep Matching Model for Online Large-scale Recommender System》
论文下载地址为：https://arxiv.org/abs/1909.00385v1

# 1、背景

像淘宝这样的大规模的推荐系统，需要快速和准确的响应用户当前的需求。淘宝推荐系统一般采用两阶段的方式。首先在召回阶段召回可能的候选集，然后在排序阶段进行精准排序推荐。

目前在淘宝的召回模型中，基本上采用的模型的基础是基于物品的协同过滤模型。但是协同过滤模型只能考虑用户的静态兴趣，而不能捕获用户的动态兴趣。这些兴趣主要通过用户的行为来体现。

在淘宝的场景中，用户的行为主要分为两种，第一个是当前的浏览session，用户在一个session中，需求往往是十分明确的，比如你想买球鞋，往往只会关注球鞋类的商品。另一个是之前的记录，一个用户虽然可能不是每次都来买球鞋，但是也可能提供一定的有用信息，比如用户只买阿迪的鞋子或者只买帆布鞋等等。因此分别建模这两种行为序列来刻画用户的兴趣，是十分有用的。

接下来，我们就来学习下如何分别刻画用户的两种行为序列，以及如何将二者融合，并最后进行物品召回的。

# 2、SDM模型

## 2.1 问题定义
用户集合U和物品集合I就不说啦，然后我们主要看看对用户行为序列的划分，按照session进行划分的规则如下：

1）日志中标记了同样的session ID
2）虽然session ID不相同，但是相邻的行为间隔小于10min
3）最长的session长度为50，超过50的划分到前一个session（我猜测是从后往前划分session 的吧）

基于上述规则，用户最近一个session的行为被认为是短期行为，表示如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b5be2968ea6cb6c3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

m是序列的长度，而与S<sup>u</sup>相隔一周以内的行为认为是用户的长期行为L<sup>u</sup>。

根据如上定义，整个的匹配框架如下：

![](https://upload-images.jianshu.io/upload_images/4155986-a07d35573d339422.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

基于用户的短期行为，通过模型计算得到向量表示s<sup>u</sup>，基于用户的长期行为，得到向量表示p<sup>u</sup>，二者在进行融合，最终得到用户的行为表示o<sup>u</sup>。通过o<sup>u</sup>和每个物品对应的向量v<sub>i</sub>计算匹配分数，并根据分数高低进行召回：

![](https://upload-images.jianshu.io/upload_images/4155986-a10da8b235a6a219.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.2 物品和用户的Embedding表示

在淘宝的推荐中，用户不仅仅关注物品本身，一些属性如品牌、店铺、价格等都是用户关注的属性。因此，我们使用不同的属性来刻画物品，如物品ID、叶子结点分类、一级分类、品牌、店铺等等，并将不同属性对应的embedding进行拼接得到物品的embedding表示：

![](https://upload-images.jianshu.io/upload_images/4155986-4c3b4b03f3bb456b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

同样的，用户也有对应的属性，如年龄区间、性别、蜂窝(学生／白领等等）。用户的embedding如下：

![](https://upload-images.jianshu.io/upload_images/4155986-37d9deace818eb4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.3 短期行为建模

短期行为建模的整体过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-f215ae52eb9336f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于短期行为，即用户最近的一个session里的行为。在将物品转换为embedding后，首先通过LSTM来进行建模：

![](https://upload-images.jianshu.io/upload_images/4155986-a0f73dd073c76366.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样，每一个物品又一个对应的hidden state的输出h。接下来，是最近经常被使用的multi-head attention，主要有两点原因：

1）用户的行为中存在一些误点击行为，通过self-attention来降低这种影响；
2）用户可能对不同物品的关注点不同。

个人感觉前面的LSTM有点多余，可以在multi-head attention中加入序列信息的吧，这样性能可能好一点。而multi-head attention的过程咱们就不多说了，可以参考我之前的文章。经过multi-head attention，对应的序列输出为：

![](https://upload-images.jianshu.io/upload_images/4155986-c32a8d370dc520b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

随后又是一层attention，这一次主要的关注点是用户可能对不同的物品偏好程度不同：

![](https://upload-images.jianshu.io/upload_images/4155986-b03014f56af0733d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样，用户的短期行为我们就通过一个向量s<sup>u</sup>表示了

## 2.4 长期行为建模

对于长期行为，咱们不像刚才那么搞，主要是性能撑不住啊，还像短期行为那么搞的话，有点像之前介绍的DSIN模型，参数有点多。我们主要关注的点在于通过长期行为来从不同角度来刻画用户的兴趣，比如用户经常逛某种类型的店铺、经常复购同一类型的商品等等。因此把长期行为中的所有物品对应的属性集合划分为不同的set，如物品IDset、物品店铺set、物品品类set等等。下图展示了长期行为的建模过程：

![](https://upload-images.jianshu.io/upload_images/4155986-4c5d3505ef9ebe74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于不同的set，都经过一个attention层进行建模，如用户可能对不同的店铺偏好程度不同，对不同的品类偏好程度不同：

![](https://upload-images.jianshu.io/upload_images/4155986-7ee1e3ba912dfaf1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样每一个set可以得到一个对应的向量，进行拼接后再经过一层全连接层得到用户的长期行为表示：

![](https://upload-images.jianshu.io/upload_images/4155986-7c62716f262729ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.5 兴趣融合

接下来的过程就很巧妙了，并非将长短期兴趣向量直接拼接，而是借鉴了LSTM或GRU中的门的概念，对短期兴趣向量和长期兴趣向量进行一个加权，过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-9bbd7b74e5ab837a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

具体的计算过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-155c73f5b73ae541.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![](https://upload-images.jianshu.io/upload_images/4155986-492c34a9af7159c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样我们就得到了用户的兴趣表示o<sup>u</sup>。

## 2.6 训练

得到了用户的兴趣表示o<sup>u</sup>之后，根据日志我们可以得到用户下一个交互的物品，作为正例，接下来，采样K-1个负例物品。将K个物品对应的embedding，分别于用户兴趣表示计算内积，作为每个物品的得分。并最终通过softmax和交叉熵来计算损失，并进行模型训练：

![](https://upload-images.jianshu.io/upload_images/4155986-084e4e66b331060a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.7 整体结构

最后再来看一下整个模型的结构：

![](https://upload-images.jianshu.io/upload_images/4155986-700d2b4676c35088.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 3、实验结果

本文的实验的代码和数据地址在： https://github. com/alicogintel/SDM.

数据集选择的是淘宝和京东的两个数据集。离线实验的评价指标包括HITRatio、精确率、召回率、F1值：

![](https://upload-images.jianshu.io/upload_images/4155986-8279cfa6bf566269.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而线上模型的评价指标主要有三个CTR、GMV和Discovery：

![](https://upload-images.jianshu.io/upload_images/4155986-30afc39c6c54c099.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

离线效果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-f585d023171b1602.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

除了基准的模型外，SDM模型有许多变体，这里也简单介绍一下：

![](https://upload-images.jianshu.io/upload_images/4155986-d2eb16951102ccb7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-df7b5db5be1c06e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在线效果对比如下，pCTR、pGMV和discovery分别提升了7.04%, 4.50% and 24.37%：

![](https://upload-images.jianshu.io/upload_images/4155986-f3eb9b9424d2c694.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



# 推荐系统遇上深度学习(六十四)-通过自注意力机制来自动学习特征组合



![](https://upload-images.jianshu.io/upload_images/4155986-7d63a22ab2c04231.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文要介绍的论文题目是《AutoInt: Automatic Feature Interaction Learning via Self-A entive Neural Networks》
论文下载地址为：t.cn/AipG8aXz

这篇文章使用Multi-Head self-Attention进行自动的特征提取，整体思路相对而言比较简单易懂，但是论文结构比较完整。除介绍论文外，最后本文介绍了如何使用Python绘制热力图，一起来看一下吧。

# 1、背景

点击率预估问题对推荐系统来说比较重要，但是目前存在许多挑战：
1）特征数量巨大，离散特征多，存在特征稀疏问题。
2）高阶特征组合对于提升点击率预估的性能至关重要，但发现一些有实际意义的特征组合需要依靠专业知识，这一过程费时费力，需要通过模型自动去学习高阶特征组合。
3）现有的方法如FM，它只能学习低阶的特征组合，而DeepFM等通过神经网络的方法往往进行隐式的特征组合，缺乏一定的可解释性。

基于上述问题，本文提出了AutoInt，通过目前比较火热的Multi-Head Attention来自动进行特征组合。一起来看一下。

# 2、AUTOINT框架

## 2.1 整体框架

AUTOINT框架的整体框架比较简单，如下图：

![](https://upload-images.jianshu.io/upload_images/4155986-80e2efdfcac26ce0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来，我们逐层进行介绍。

## 2.2 输入层

这里咱们的目标是预测用户u点击某个物品i的概率，因此输入层包含用户相关的特征和物品相关的特征：

![](https://upload-images.jianshu.io/upload_images/4155986-0cca76b68f5b12fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上面的M是特征域的个数，一个离散特征和一个连续特征都属于一个单独的特征域。

## 2.3 Embedding层

在Embedding层，我们对三种不同的特征分别进行了处理，这三种特征分别是单值离散特征、多值离散特征和连续特征。

对于单值离散特征，直接通过Embedding词表得到对应的Embedding表示：

![](https://upload-images.jianshu.io/upload_images/4155986-fea50c67c6f5123c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于多值离散特征，通过Embedding词表得到对应Embedding之后，还需要通过avg-pooling的方式对同一个field的Embedding进行平均：

![](https://upload-images.jianshu.io/upload_images/4155986-55ec13de1dca7aa9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上面的q就是多值离散特征中取值的个数。对于离散特征来说，上面的x<sub>i</sub>是one-hot向量或者multi-hot向量，取值非0即1，而对于连续特征，直接就是一个标量，我们将标量的取值直接与其对应的Embedding相乘：

![](https://upload-images.jianshu.io/upload_images/4155986-214113cd2050ec18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.4 交互层

交互层是Transformer的encoder部分，由多层进行堆叠来学习特征之间的高阶组合。Transformer中最重要的是multi-head attention，其简单的示意图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-3acb34a8e38fdfb0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

有关Transformer，咱们这里也不讲了，可以参考之前的文章。

## 2.5 输出层

输出层的计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-936c0ebd205b9d78.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

首先将交互层得到的输出进行对位相加，然后经过一层全连接层并进行sigmoid变换得到点击率的预估值。

而模型的损失采用的是logloss：

![](https://upload-images.jianshu.io/upload_images/4155986-e4a202b862a58212.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.6 特征组合学习

接下来，我们来解释一下，模型是如何来学习高阶特征之间的组合的。假设我们有4个field的输入，分别是x<sub>1</sub>、x<sub>2</sub>、x<sub>3</sub>、x<sub>4</sub>。这里重点介绍二阶和三阶特征组合。

**二阶特征组合**

在第一层的交互层，通过attention map我们可以学习不同特征的相关性，并通过加权求和的方式进行组合。假设第一个field的输出为e<sub>1</sub>，e1中就包含了第一个field和4个field之间的交互。

**三阶特征组合**

对于三阶特征组合，在第二层的交互层就可以学习到。我们知道，在transformer中encoder的每一个block中，存在residual connection的过程，这样输出e<sub>1</sub>中不仅包含了第一个field和其他field组合的信息，还包含第一个field自身的信息，这样在与e<sub>3</sub>(第三个field在第一个交互层的输出)进行multi-head attention时，就可以得到第一个field和第二三个field的交互结果。

# 3、实验结果

## 3.1 实验结果分析

文中使用了不同的数据集，与一些base模型进行了效果的对比，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-9fa8f3c041c9ee8e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，AutoInt在所有的数据集上，AUC都是最优的。

## 3.2 可解释性分析

最后再来看看如何对推荐过程中的特征组合进行一定的解释性分析，这主要需要观察multi-head attention过程中的attention map：

![](https://upload-images.jianshu.io/upload_images/4155986-26c759b1a62fcf2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中，左边是针对一条电影推荐数据的结果，对于该条数据，通过attention map可以得到的结论是18-24岁的年轻人比较喜欢看恐怖片或者动作片。

而右图是对所有训练数据集中对应field的attention score的一个平均值，可以看到性别和电影类别、年龄和电影类别等都具有更高的相关性。

# 4、Python绘制热力图

论文整体上就介绍完了。有一说一，整体上的创新点不是很足，不过相比于其他的论文，对于特征组合的构建、以及可解释性的分析比较充分，论文结构相对来说更加完整。最后，咱们也一起来学习一下3.2节中提到的热力图的绘制：

```
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# cmap(颜色)


np.random.seed(20180316)

x = np.random.randn(4, 4)

f, (ax1, ax2) = plt.subplots(figsize=(6,6),nrows=2)

sns.heatmap(x, annot=True, ax=ax1)

sns.heatmap(x, annot=True, ax=ax2, annot_kws={'size':9,'weight':'bold', 'color':'blue'})

plt.show()
```

上面结果的如下：

![](https://upload-images.jianshu.io/upload_images/4155986-243a6601cf7ec724.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中，最重要的函数是sns.heatmap函数，这里我们用到了四个参数，第一个参数是我们的输入数据，也就是热度矩阵，这里是4*4大小的；第二个参数是annot，代表是否要标注热力值大小，默认为false；第三个参数ax是指定我们的画布；第四个参数annot_kws是对显示的字体进行一定的设定。

好了，今天就到这里了，大伙假期注意劳逸结合哇！



# 推荐系统遇上深度学习(六十五)-负采样点击率修正的那些事

本来想写蚂蚁金服运用强化学习做推荐的文章《Generative Adversarial User Model for Reinforcement Learning Based Recommendation System》，但这不快放假了嘛，思考再三还是决定写点简单的吧。这次来谈谈负采样点击率修正的那些事。

# 1、负采样点击率修正

在广告点击率预估中，正负样本的比例是很不平衡的，所以有时候需要进行一定程度的负采样，即对负样本进行一定比例的采样，降低正负样本不平衡的程度，一定程度上提高模型预估的精度。

假设整体样本中的正负样本比例为1:3（当然实际上会比这更不平衡的多，此处仅仅是举个例子），由于假设训练集和测试集中的样本是独立同分布的，那么由不采样的数据训练得到的模型，在测试集上的点击率平均值约为0.25。

再假设样本中存在三种广告的样本A、B和C，其比例为50:30:20，而各自的正样本分别占30%、20%和20%，如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-880a224874d392ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样，在测试集中，对三种广告的点击率预估值的平均值也接近0.3、0.2和0.2。此时我们对负样本进行一定程度的采样，假设采样率为1/3，这样能使整体上正负样本比例保持在1:1，但是具体到A、B和C三种类型的广告，其比例就不确定了，咱们具体来算一下，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-233c7648c69b35fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

要注意上图中，我们仅仅是将负样本占比除以3。这样算出的A、B和C三种类型的广告的点击率的平均值仍满足A>B=C。这样是保序的，我们会把A广告排在最前面。但是在广告场景中，不仅仅要考虑点击率，还要考虑每次点击带来的收益，假设A、B、C三种广告的收益CPC（cost per click，每次点击收益）分别是6、8、3，那么三种广告每次曝光带来的期望收益是1.8、1.6和0.6，排序顺序为A、B、C：

![](https://upload-images.jianshu.io/upload_images/4155986-1a47dc7c6a742b93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而在采样后，三种广告每次曝光带来的期望收益是3.38、3.43和1.29，排序变为了B、A、C。

![](https://upload-images.jianshu.io/upload_images/4155986-5d8051aa86bd8720.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因此样本采样虽然可能带来更好的模型精度，但是在广告场景中，需要对点击率进行修正，修正公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-bda8cb99eea7c4c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中，q是修正后的点击率，p是采样后的预测点击率、w是采样率，推导过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-394394b5c38b36ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

再来看刚才的结果，使用修正公式后点击率和采样前相同：

![](https://upload-images.jianshu.io/upload_images/4155986-4bf524b50512e5ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

好了，本文就到这里了，祝大家假期快乐！



# 推荐系统遇上深度学习(六十六)-[阿里]基于多任务学习的CVR预估模型ESM2

![](https://upload-images.jianshu.io/upload_images/4155986-2dbb27042ce92176.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

今天介绍的文章名称是《Conversion Rate Prediction via Post-Click Behaviour Modeling》
论文下载地址为：https://arxiv.org/abs/1910.07099

在本系列的第十九篇文章中，我们已经介绍过一种基于多任务学习的CVR预估模型ESMM，同样是阿里发表的论文。本文可以看作是ESMM的升级版，一起来学习一下吧。

# 1、背景

一个包含推荐系统、用户行为的完整电商推荐流程如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-95aad925a0413464.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

主要分为两个部分，一是推荐阶段，二是用户行为阶段。推荐阶段大都分为召回和精排两部分，精排之后有时候会通过一些规则进行打散，然后展示给用户。用户看到推荐的物品，称作Impression（可翻译为曝光），用户看到自己感兴趣的物品，会Click（点击），如果觉得还不错，会Buy（购买）。因此用户行为阶段的一般过程是Impression - Click - Buy。

此时我们就会有两个主要的概念：**CTR**和**CVR**，同时这两个指标也是电商推荐系统所要预估的重点部分。CTR是曝光到点击的概率，而CVR是点击到购买的概率。

传统的CVR预估问题存在两个主要的问题，一是**样本选择偏差(sample selection bias,SSB)**，二是**数据稀疏(data sparsity,DS)**，如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-30e379c52a298055.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**样本选择偏差(sample selection bias,SSB)**：假设把给用户曝光过的产品看作是整个样本空间X，用户点击过的产品仅是中间的部分，定义为Xc。传统的推荐系统仅用Xc中的样本来训练CVR预估模型，但训练好的模型是在整个样本空间X去做推断的。由于点击事件相对于曝光事件来说要少很多，因此只是样本空间X的一个很小的子集，从Xc上提取的特征相对于从X中提取的特征而言是有偏的，甚至是很不相同。从而，按这种方法构建的训练样本集相当于是从一个与真实分布不一致的分布中采样得到的，这一定程度上违背了机器学习中独立同分布的假设。这种训练样本从整体样本空间的一个较小子集中提取，而训练得到的模型却需要对整个样本空间中的样本做推断预测的现象称之为样本选择偏差。样本选择偏差会伤害学到的模型的泛化性能。

**数据稀疏(data sparsity,DS)**:推荐系统展现给用户的商品数量要远远大于被用户点击的商品数量，同时有点击行为的用户也仅仅只占所有用户的一小部分，因此有点击行为的样本空间Xc相对于整个样本空间X来说是很小的，通常来讲，量级要少1~3个数量级。这就是所谓的训练数据稀疏的问题，高度稀疏的训练数据使得模型的学习变得相当困难。

为解决上述两个问题，阿里曾经发表过多任务学习模型ESMM，简单回顾一下：

![](https://upload-images.jianshu.io/upload_images/4155986-e583e6dbf39b38d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200)

ESMM中有两个子网络，二者共享Embedding部分，分别输出CTR预估值pCTR和CVR预估值pCVR。Loss分为两部分，一是CTR预估带来的loss，二是pCTCVR（pCTR * pCVR）带来的loss。这样就可以在整个样本空间上训练CVR预估模型。

但是对于CVR预估来说，ESMM模型仍然面临一定的样本稀疏问题，毕竟从点击到购买的样本非常少。但挖掘用户行为，发现用户在购买前往往会有其他的行为，比如把想要购买的物品加入购物车或者心愿单。如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-edc83c1ec5d27fc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

加入心愿单／购物车的数据相较购买数据还是比较多的，因此可以基于这部分数据，通过多任务学习模型来求解CVR模型。如图所示，文中把加入购物车或者心愿单此类行为称作Deterministic Action (DAction) ，而其他对购买相关性不是很大的行为称作Other Action(OAction) 。此时原来的 Impression→Click→Buy过程变成了更加丰富的Impression→Click→DAction/OAction→Buy过程。

本文提出的模型基于Impression→Click→DAction/OAction→Buy过程来建模CVR预估问题，称作Elaborated Entire Space Supervised Multi-task Model(ESM<sup>2</sup>)，一起来看下吧。 

# 2、ESM<sup>2</sup>模型介绍

## 2.1 模型整体架构

模型整体架构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-19ae6cb4b7446c39.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，一共有四个任务，分别是：

**Y1**:点击率
**Y2**:点击到发生DAction的概率
**Y3**:发生DAction到购买的概率
**Y4**:发生OAction到购买的概率

这里好像少了一个从点击到OAction的概率，这是因为DAction和OAction是对立事件。

因此，此时CVR = (1 - Y2) * Y4 + Y2 * Y3

## 2.2 模型细节

上述的四个子任务，其用的样本相同的，在整个样本空间中进行训练。其输入首先经过**共享嵌入模块（Shared Embedding Module (SEM)）**转换为对应的嵌入向量，随后通过四个独立的神经网络分别预估Y1、Y2、Y3和Y4。

## 2.3 损失函数

既然是在整个样本空间上的学习，那么计算的损失必须是从Impression开始的，那么计算损失首先需要计算下面三个部分：

**pCTR**：Impression→Click的概率直接由第一个网络的结果得出
**pCTAVR**：Impression→Click→DAction的概率，pCTAVR = Y1 * Y2，由前两个网络的输出结果相乘得到
**pCTCVR**：Impression→Click→DAction/OAction→Buy的概率，pCTCVR = CTR * CVR = Y1 * [(1 - Y2) * Y4 + Y2 * Y3]，由四个网络的输出共同得到。

随后通过三个logloss分别计算三个部分的损失：

![](https://upload-images.jianshu.io/upload_images/4155986-d626851a84939023.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-7a2fb6f6d75769d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-bf91010a81ef62d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而完整的损失函数由三部分加权得到：

![](https://upload-images.jianshu.io/upload_images/4155986-c6968d7bab309c85.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而在预测时，只需要经过后三个网络，便可以计算对应的CVR。

# 3、实验结果

本文对比了几个模型在CVR预估上的效果：

**GBDT**
**DNN**使用Click→Buy的样本来训练CVR模型，使用Impression→Click的样本来训练CTR模型
**DNN-OS**，对Click→Buy的样本进行过采样，其他同DNN
**ESMM**
**ESM<sup>2</sup>**

评价指标包括AUC和GAUC，GAUC是对每个用户的AUC进行加权的结果：

![](https://upload-images.jianshu.io/upload_images/4155986-7fc96abd603d631e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

实验结果表明本文提出的ESM<sup>2</sup>模型在CVR预估上表现较为突出：

![](https://upload-images.jianshu.io/upload_images/4155986-58202c84bf90d608.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

好了，本文介绍就到这里，其他的实验结果以及模型的一些细节，大伙可以阅读原论文。



# 推荐系统遇上深度学习(六十七)-计算广告中的COEC简介

最近工作中接触比较多的是COEC（Click on Expected Click），本篇文章就来简单介绍一下其概念。

在《计算广告》一书中，已对其概念做出了介绍，感兴趣的同学也可以进行参考。

当给你两个广告，广告A的点击率是0.3，广告B的点击率是0.2，那能说明广告A的质量好于广告B么？单从点击率来看，确实是这样的，但假设我再告诉你曝光数据：

![](https://upload-images.jianshu.io/upload_images/4155986-fa3a7324fe1f280e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

哇，可以看到广告A和广告B都曝光了10次，广告A的曝光位置一般比较靠前，广告B的曝光位置一般比较靠后。我们都知道，广告排在越靠前，点击率一般较高，而越靠后，点击率一般都比较低。你是否开始怀疑前面的结论是否准确了呢？此时我在告诉你每个位置的点击率数据：

![](https://upload-images.jianshu.io/upload_images/4155986-7dc5e70f61e82c63.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这个期望点击率，我们在后面再来介绍如何得到。有了这个点击率的数据，我们就可以计算广告A和广告B的期望点击次数：sum(每个位置的曝光 * 每个位置的期望点击率）：

![](https://upload-images.jianshu.io/upload_images/4155986-1737419b61d48934.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，广告A的期望点击次数是5.1次，广告B的期望点击次数是2.85次，但是广告A实际点击了3次，广告B实际点击了2次。那么我们是不是可以拿实际点击数和期望点击数的比值来更准确的判断广告质量的好坏呢？是的，实际点击数除以期望点击数，便是本文要介绍的COEC：

![](https://upload-images.jianshu.io/upload_images/4155986-bc0c0825587d69eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过COEC的计算，我们看到，其实是广告B的质量更加好。

讲到这里，其实你应该能够大致明白COEC是怎么回事了，它更能够准确表示某个广告的实际点击率水平，能够一定程度上消除位置和其他因素的偏差对于点击率的影响。

最后再讲一点每个位置期望点击率的计算，这里简单讲三种方法：
1、最简单的一种方法就是直接统计每个位置上的点击率，但这么做并不十分恰当，一个影响最大的因素就是广告质量。在推荐系统中，排在后面的广告本身的质量一般比前面的差，广告质量的差距会导致后面位置的期望点击率偏低。

2、第二种方法是搞一个小流量实验组，对广告进行随机排序，这样一段时间后，再统计每个位置的点击率。这样做的话广告质量的影响基本消除了，缺点就是不够个性化。

3、第三种方法就是训练一个模型了，基于用户和上下文特征去预测每个位置的点击率p<sub>bias</sub>(u,c)。具体训练的方法这里就不再介绍了。

好了，你们弄懂COEC是怎么回事了么？



# 推荐系统遇上深度学习(六十八)-建模多任务学习中任务相关性的模型MMoE

![](https://upload-images.jianshu.io/upload_images/4155986-ee946d93b3ea1103.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文题目是：《Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts》
论文下载地址为：https://dl.acm.org/citation.cfm?id=3220007

多任务学习最近越来越受欢迎，咱们前面也介绍过几篇阿里多任务学习的模型，不过多任务学习的效果受不同任务之间的相关性影响较大，因此本文基于**Mixture-of-Experts (MoE)**模型，提出了一种显式建模任务相关性的模型**Multi-gate Mixture-of-Experts (MMoE)** ，一起来学习一下。

# 1、背景

近年来，深度神经网络的应用越来越广，如推荐系统。推荐系统通常需要同时优化多个目标，如电影推荐中不仅需要预测用户是否会购买，还需要预测用户对于电影的评分，在比如电商领域同时需要预测物品的点击率CTR和转化率CVR。因此，多任务学习模型成为研究领域的一大热点。

许多多任务学习模型取得了不错的效果，但是实践中多任务学习模型并不总比单任务模型效果更突出。这主要是因为不同任务之间的相关性低（如数据的分布不同等等）导致的。

是不是真的如上述所说，任务之间的相关性会影响多任务学习的效果呢，咱们先在第二节中做一个实验。

# 2、任务相关性实验

## 2.1 一般的多任务学习模型框架

一般的多任务学习模型框架如下：

![](https://upload-images.jianshu.io/upload_images/4155986-e42e5f34ed5de512.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于不同的任务，底层的参数和网络结构是共享的，然后上层经过不同的神经网络得到对应任务的输出。 假设底层输出是f(x)，那么第k个任务的输出y<sub>k</sub>为：

![](https://upload-images.jianshu.io/upload_images/4155986-cb6451e07fcc5ce3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中h<sup>k</sup>是第k个任务上层神经网络的参数。

## 2.2 任务相关性实验

接下来，我们通过一个实验来探讨任务相关性和多任务学习效果的关系。

假设模型中包含两个回归任务，而数据通过采样生成，并且规定输入相同，输出label不同。那么任务的相关性就使用label之间的皮尔逊相关系数来表示，相关系数越大，表示任务之间越相关，数据生成的过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-ae8c882cff1e25ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

首先，生成了两个垂直的单位向量u<sub>1</sub>和u<sub>2</sub>，并根据两个单位向量生成了模型的系数w<sub>1</sub>和w<sub>2</sub>，如上图中的第二步。w<sub>1</sub>和w<sub>2</sub>之间的cosine距离即为p，大伙可以根据cosine的计算公式得到。

随后基于正态分布的到输入数据x，而y根据下面的两个式子的到：

![](https://upload-images.jianshu.io/upload_images/4155986-5a54494cb9b6ca1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

注意，这里x和y之间并非线性的关系，因为模型的第二步是多个sin函数，因此label之间的皮尔逊相关系数和参数w<sub>1</sub>和w<sub>2</sub>之间的cosine距离并不相等，但是呈现出一个正相关的关系，如下图：

![](https://upload-images.jianshu.io/upload_images/4155986-c9431a0375b331d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因此，本文中使用参数的cosine距离来近似表示任务之间的相关性。

## 2.3 实验结果

基于上述数据生成过程以及任务相关性的表示方法，分别测试任务相关性在0.5、0.9和1时的多任务学习模型的效果，如下图：

![](https://upload-images.jianshu.io/upload_images/4155986-25940cb5fb4f4ea6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到的是，随着任务相关性的提升，模型的loss越小，效果越好，从而印证了前面的猜想。

# 3、MMoE模型

## 3.1 MoE模型

先来看一下**Mixture-of-Experts (MoE)**模型（文中后面称作 One-gate Mixture-of-Experts (OMoE)），如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-c7b580aa40f1c24b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，相较于一般的多任务学习框架，共享的底层分为了多个expert，同时设置了一个Gate，使不同的数据可以多样化的使用共享层。此时共享层的输出可以表示为：

![](https://upload-images.jianshu.io/upload_images/4155986-e78e96f563e3b30e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中f<sub>i</sub>代表第i个expert的输出，g<sub>i</sub>代表第第i个expert对应的权重，是基于输入数据得到的，计算公式为g(x) = softmax(W<sub>g</sub>x)。

## 3.2 MMoE模型

相较于MoE模型，**Multi-gate Mixture-of-Experts (MMoE)**模型为每一个task设置了一个gate，使不同的任务和不同的数据可以多样化的使用共享层，模型结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-392a8f5ccf998a75.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

此时每个任务的共享层的输出不同，第k个任务的共享层输出计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-3a90b8611e9acb3e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-c14d44d0d65eae03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

随后每个任务对应的共享层输出，经过多层全连接神经网络得到每个任务的输出：

![](https://upload-images.jianshu.io/upload_images/4155986-5e90876aab379e5b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

从直观上考虑，如果两个任务并不十分相关，那么经过Gate之后，二者得到的权重系数会差别比较大，从而可以利用部分expert网络输出的信息，近似于多个单任务学习模型。如果两个任务紧密相关，那么经过Gate得到的权重分布应该相差不多，类似于一般的多任务学习框架。

# 4、实验结果

先回顾上面介绍的三种多任务学习的架构：

![](https://upload-images.jianshu.io/upload_images/4155986-31037718869cf80a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

实验分为三部分：人工合成数据集（即本文第二部分所介绍的人工生成的数据集）、UCI census-income dataset和Large-scale Content Recommendation

## 4.1 人工合成数据集-实验结果

![](https://upload-images.jianshu.io/upload_images/4155986-db447429ed2ac93d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 4.2 UCI census-income dataset-实验结果

这块文中介绍了几种多任务学习的模式，这里就不过多介绍了。

![](https://upload-images.jianshu.io/upload_images/4155986-fc02386f7f7f685b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 4.3 Large-scale Content Recommendation-实验结果

![](https://upload-images.jianshu.io/upload_images/4155986-e75ff2a9eb931202.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这篇论文的介绍就到这里啦，这一篇是在我阅读youtube多任务学习论文中发现的，所以下一篇会介绍youtube今年的论文《Recommending What Video to Watch Next: A Multitask Ranking System》，期待一下吧。

可能我的理解还有不到位的地方，欢迎大家一起讨论对这篇文章的理解~

![](https://upload-images.jianshu.io/upload_images/4155986-c793bfe88d300871.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/430)



# 推荐系统遇上深度学习(六十九)-youtube视频推荐中的多任务排序系统

![](https://upload-images.jianshu.io/upload_images/4155986-034c1035a6c7b685.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的文章是：《Recommending What Video to Watch Next: A Multitask Ranking System》

在上一篇文章中，我们介绍了一种多任务学习的模型**Multi-gate Mixture-of-Experts (MMoE)** ，而本文介绍的youtube视频推荐模型，就用到了这种多任务学习的框架。除此之外，本文还介绍了如何消除推荐系统中常见的位置偏置因素以及在应用深度学习模型中的一些实践经验，一起来学习一下。

# 1、背景

视频推荐的任务可以描述为根据用户当前所观看的视频，来预测用户下一个可能观看的视频。传统的推荐系统往往是两阶段的设计模式，即召回和精排阶段。本文主要介绍精排阶段的模型。

![](https://upload-images.jianshu.io/upload_images/4155986-bd7bb337e0c07e47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

设计和部署一个大型的视频推荐系统充满了许多挑战，比如以下几条：
1）视频推荐中有多个不同甚至可能发生冲突的目标，比如除用户是否会观看外，还希望去预测用户对于视频的评分，以及是否会分享给朋友。
2）在推荐系统往往存在一些隐式的偏置信息。比如用户是否会点击和观看某个视频，并不一定是因为他喜欢，可能仅仅是因为它排在前面，因此导致训练数据可能是有偏的。这也是咱们经常遇到的**位置偏置**问题。

为了解决以上的挑战，youtube采用了一种多任务学习框架，该框架基于**Multi-gate Mixture-of-Experts (MMoE)**，一起来学习一下吧。

# 2、模型介绍

## 2.1 视频推荐问题描述

构建一个视频推荐框架，除在上一节中介绍的一些挑战外，还有其他一些因素需要考虑：
1）**Multimodal feature space**：视频推荐模型需要考虑特征众多，比如视频本身内容、预览图、声音、标题和文字描述、上下文特征等等。
2）**Scalability**：模型的线上性能需要得到保证。通常通过两阶段（召回和精排两阶段）来保证性能问题。

接下来介绍一下召回和精排两阶段的内容。在召回阶段，使用多路召回的方式生成一个小规模的候选集。比如，通过主题匹配度的召回、根据与当前观看视频同时观看的频率进行召回、基于模型的召回方式等等。而在精排阶段，则采用深度神经网络来对召回阶段得到的小规模候选集进行排序。

接下来，详细介绍精排阶段的模型框架。

## 2.2 整体框架

模型的整体框架如下：

![](https://upload-images.jianshu.io/upload_images/4155986-3fdfd853201dd176.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来介绍一些细节。

## 2.3 排序目标

这里使用用户行为来作为训练的Label。用户可能会有不同方面的行为，每种不同的行为都可以视为一个排序目标。这些排序目标主要分为两大类：

**engagement objectives**：这类目标主要考虑用户点击和观看行为。通过二分类模型来预测用户的点击行为，而通过回归模型来预测用户观看视频的时长。

**satisfaction objectives**：这类目标主要考虑用户在观看视频之后对于视频的反馈。使用二分类模型来预测用户是否会点击喜欢该视频，而通过回归模型来预测用户对于视频的评分。

针对上述不同的目标，使用一个多任务学习模型来进行训练。而在应用阶段，把每一个候选视频输入到多任务学习模型中，来得到各个子任务的输出结果，通过加权的方式来输出一个综合的推荐评分，从而进行排序。而不同网络结果的权重，通过人工调节来实现。

## 2.4 多任务模型

这里多任务模型借鉴了本系列上一篇中所提到的**Multi-gate Mixture-of-Experts (MMoE)**模型，使不同的任务和不同的数据可以多样化的使用共享层。这里简单回归一下模型的结构：

![](https://upload-images.jianshu.io/upload_images/4155986-df9b4bfc78751ceb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中左图是一般的MTL框架，右侧是MMoE。此时每个任务的共享层的输出不同，第k个任务的共享层输出计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-3a90b8611e9acb3e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-c14d44d0d65eae03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

随后每个任务对应的共享层输出，经过多层全连接神经网络得到每个任务的输出：

![](https://upload-images.jianshu.io/upload_images/4155986-5e90876aab379e5b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.5 建模和消除位置偏置

CTR预估问题往往存在位置偏置信息，在Youtube中，不同位置的点击率差别很大：

![](https://upload-images.jianshu.io/upload_images/4155986-de96d260d60d73a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

不同位置的点击率差异主要来自于推荐结果相关性以及位置偏置。

消除推荐系统中的位置偏置，一种常见的做法是在训练阶段将位置作为一个特征加入到模型中，而在预测阶段置为0或者一个统一的常数，如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-cf4078756c22cf59.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

还有一种做法是在训练阶段将点击率拆解为两个部分，即用户看到物品的概率 * 用户看到物品后点击的概率，而在测试阶段只预估用户看到物品后点击的概率，示意图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b0810e64da8f2066.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而本文的做法与上面两种方式都不相同，示意图如下：

![](https://upload-images.jianshu.io/upload_images/4155986-dd3368c8ff9e6fe9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过一个**shallow tower（可理解为比较轻量的模型）**来预测位置偏置信息，输入的特征主要是一些和位置偏置相关的特征。在多任务模型的子任务最后的sigmoid前，将shallow tower的输出结果加入进去。而在预测阶段，则不考虑shallow tower的结果。

值得注意的是，位置偏置信息主要体现在CTR预估中，而用户观看视频是否会点击喜欢或者用户对视频的评分，这些是不需要加入位置偏置信息的。

# 3、实验及结果

这里主要对比了两个模型，一个是一般的MTL结构，一个是MMoE结构。对于评价指标，线下采用AUC，线上采用A／B test的方式，来观测实验组和对照组的停留时间、好评率等等指标，实验结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-d688ee0b2b4dcc11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可能我的理解还有不到位的地方，欢迎大家一起讨论对这篇文章的理解~

![](https://upload-images.jianshu.io/upload_images/4155986-c793bfe88d300871.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/430)

关注小编的公众号，后台回复“进群”，一起来交流学习推荐系统吧！



# 推荐系统遇上深度学习(七十)-[阿里]推荐中的个性化重排序

![](https://upload-images.jianshu.io/upload_images/4155986-413dba005eda5872.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文是：《Personalized Re-ranking for Recommendation》
下载地址：https://arxiv.org/abs/1904.06813

排序是推荐系统中比较重要的一环，一般通过point-wise的方式对每一个物品计算一个得分，然后进行排序。但这样做只考虑了单个物品与用户之间的相关性，而忽略了物品之间的相互影响。因此本文在排序阶段后设计了一个**重排序（Re-ranking）**的模块，在考虑物品相关性的情况下对排序结果进行重排，一起来看一下。

# 1、背景

排序阶段是推荐系统中比较重要的一环，排序的质量直接影响了用户的体验以及平台的收益。排序算法整体可分为point-wise、pair-wise和list-wise。出于性能上的考虑，一般采用point-wise的方法，即对每一个候选物品给出一个评分，基于评分进行排序。这样的做法仅仅考虑了用户和物品之间的关系，而没有考虑排序列表中物品之间的关系。而pair-wise和list-wise的方法尽管将物品对或者物品列表作为整体输入，但也仅仅是尽可能优化损失函数，而并没有从特征空间上显式建模物品间的相互影响。（文中的这句话没有太明白）

一些文章通过建模物品之间的相互影响来对排序阶段给出的排序结果进行微调，这种做法叫做**重排序（Re-ranking）**。主流的方法是基于RNN的重排序。但是RNN对于建模物品之间的影响有一定的缺陷，如果两个物品相隔较远，它们的相关性并不能很好的刻画。

因此本文提出了一种基于Transformer的重排序结构，相较于RNN，其优势主要体现在两个方面：
1）两个物品的距离不会影响其相关性的计算
2）Transformer是并行计算，编码效率相较于RNN更为高效（RNN一个时刻只能输入一个物品，相当于是串行计算，而Transformer可以同时输入所有物品，是并行计算）

除了使用Transformer之外，本文还有一个值得借鉴的地方就是将用户特征加入了Transformer中，使得重排序更加个性化。接下来就一起看一下阿里是如何进行个性化重排序的。

# 2、模型介绍

## 2.1 整体介绍

重排序的整体框架如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-141c6bc5c421e04a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

主要分为三个部分，输入层、编码层和输出层。文中用到的一些符号定义如下：

![](https://upload-images.jianshu.io/upload_images/4155986-ee460fee936eaab5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.2 输入层

首先，经过排序阶段，我们得到了固定长度的列表S=[i<sub>1</sub>,i<sub>2</sub>,...,i<sub>n</sub>]，每个物品对应一个特征向量x<sub>i</sub>，长度为d<sub>feature</sub>，此时输入计作**E**。除此之外，输入层还包含两个部分。

**个性化向量Personalized Vector (PV)**：用户和每一个物品之间都会计算一个个性化向量pv<sub>i</sub>作为输入，个性化向量通过如下的预训练模型得到：

![](https://upload-images.jianshu.io/upload_images/4155986-649d0ba698ff4d1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

该模型是一个二分类模型，取最后一个layer的输出作为个性化向量pv<sub>i</sub>。

加入个性化向量之后，输入矩阵**E'**为：

![](https://upload-images.jianshu.io/upload_images/4155986-7c5dcb70f756ca34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**位置编码信息Position Embedding (PE)**：与Transformer中固定的编码信息不同，这里的位置编码信息是可以学习，位置编码矩阵和**E'**大小相同，计作PE，此时模型的输入**E''**为：

![](https://upload-images.jianshu.io/upload_images/4155986-41bb91cf1aadd220.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在得到**E''**之后，经过一个单层的前向网络来进行一定的转换：

![](https://upload-images.jianshu.io/upload_images/4155986-60465c5611886c14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中等式右边的**E**应该是**E''**吧，感觉打错了。

## 2.3 编码层

编码层是Transformer结构：

![](https://upload-images.jianshu.io/upload_images/4155986-f2e22d4a5648662b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

有关Transformer，我们之前有篇文章详细介绍过，这里就不再赘述，大家可以参考：https://www.jianshu.com/p/2b0a5541a17c

## 2.4 输出层

假设第N<sub>x</sub>个Transformer encoder block的输出为F<sup>(N<sub>x</sub>)</sup>，通过一层全连接神经网络和softmax层得到每个物品的重排序得分score(i)。

![](https://upload-images.jianshu.io/upload_images/4155986-e54392aa9c54e3c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

并基于交叉熵损失函数来进行模型参数的更新：

![](https://upload-images.jianshu.io/upload_images/4155986-7901da4de9332b1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 3、实验结果

文中使用Precision@k和MAP@k 作为评价指标，两个指标的计算方式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-1b23c5b0e2a48d26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-579a0aeffbc125ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

有关推荐系统的评价指标，可以看本系列的第十六篇文章：https://www.jianshu.com/p/665f9f168eff

## 3.1 线下实验结果

首先，在Yhaoo Letor数据集上使用两个模型得到的最初推荐结果，分别使用不同的模型进行重排序，实验结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-9b362075b4c007fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来，分析了不同的模型结构所对应的实验结果：

![](https://upload-images.jianshu.io/upload_images/4155986-e4d82d00e12276d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

最后，使用真实的电商数据集进行试验，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-9157d6f6c55308e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 3.2 线上A／B实验结果

线上使用了三个模型进行A／B实验，实验的评价指标包括PV、IPV、CTR和GMV。PV指24小时内店铺内所有页面的浏览总量，可累加。IPV指点击进入宝贝详情页的次数。如果用户看的越多、点击次数越多，也可以一定程度上表示模型排序结果更好。

线上实验结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-bf918cf0f76f162e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 4、总结

这篇文章主要介绍通过Transformer对排序结果进行重排序。个人感觉比较创新的点在于如何将Transformer和用户特征进行结合，并提出了一种预训练的模型来得到用户的个性化向量。

但文中并没有给出直接将这个模型应用于排序阶段的效果如何，这一点也是我个人比较好奇的地方，感觉这个模型直接用在排序阶段也可以得到比较好的结果，哈哈。

本文介绍就到这列，可能我的理解还有不到位的地方，欢迎大家一起讨论对这篇文章的理解~


# 推荐系统遇上深度学习(七十一)-[华为]一种消除CTR预估中位置偏置的框架

![](https://upload-images.jianshu.io/upload_images/4155986-841c1becf9633f39.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文是：《PAL: A Position-bias Aware Learning Framework for CTR Prediction in Live Recommender Systems》
论文下载地址为：https://dl.acm.org/citation.cfm?id=3347033

在之前的youtube论文介绍中，曾经简单介绍过一些解决位置偏置的方法，本文来详细介绍下华为提出的解决广告推荐中位置偏置的方法。

# 1、背景

在广告推荐场景中，为了最大化广告收入，往往通过CTR * BID（BID是广告被点击一次平台所能获得的收入）对广告进行排序，BID基于广告主的出价，一般来说是平台不能控制的（当然有些平台有智能出价或者OCPC等调价方式），所以CTR预估显得至关重要。

一般的推荐系统，通过收集用户和广告的交互信息，来离线训练点击率预估模型，并应用于线上。但用户和广告的交互信息中存在一个很重要的影响因素，那就是广告的展示位置。

对于不同的位置来说，点击率是不同的，展示位置越靠前，则点击率越高。对于同一个广告来说，当它展示位置越靠前时，点击率同样是越高的，下面的两张图证明了这一点：

![](https://upload-images.jianshu.io/upload_images/4155986-0a4927d34b66bffd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这也就是说，收集到的训练样本中存在**位置偏置(position bias)**信息，用户点击某个广告，并非出于喜好，有可能仅仅与展示位置有关。所以在建模过程中有必要对这一部分位置偏置信息进行建模。

下一节中，我们来介绍一些消除位置偏置的方法。

# 2、解决位置偏置方法

首先我们假设收集到的离线训练数据为S={(x<sub>i</sub>,pos<sub>i</sub>->y<sub>i</sub>)}，其中x<sub>i</sub>是特征向量，包括用户特征、广告特征、交互特征和上下文特征，pos<sub>i</sub>是广告展示的位置，y<sub>i</sub>是用户的点击结果。

一般的解决位置偏置的方法有两种，作为特征（as a feature）和作为模块（as a module）

## 2.1 位置信息作为特征

该方法的示意图如下所示：

![](https://upload-images.jianshu.io/upload_images/4155986-77d75338536b7ec7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

该方法把位置信息作为特征。在离线训练时，输入特征是特征向量和位置信息的拼接[x,pos]，而在线上推断时，我们无法获取实时的位置信息，那么此时的做法有两种：

第一种做法就是一种暴力探索的方法，首先固定位置为1，然后计算所有广告相应的点击率，将点击率最高的一个广告放在第一个位置，接下来在固定位置为2，计算剩余广告相应的点击率，将点击率最高的广告放在第二个位置，依次类推。这样的做法显然是不可取的，主要是计算复杂度太高，线上性能无法保证。

第二种做法是当前工业界最为常见的做法，即固定为某一个位置，计算每个广告在该位置下的点击率，从而进行排序。但是，位置不同，所得到的推荐结果也相差很大，所以我们需要找到一个合适的位置，来得到最好的线上效果。此时往往需要通过线下评估的方式，即通过不同位置在相同测试集上的表现，来决定线上使用哪个位置。显然这种做法泛化性也是无法得到保证的。

## 2.2 位置信息作为模块

上面分析了将位置信息作为特征输入的不足之处，因此本文提出了一种将位置信息作为一个模块单独预测的方法，将在第三节中进行介绍。

值得一提的是，youtube在论文《Recommending What Video to Watch Next: A Multitask Ranking System》中也提出了一种作为模块的方法，来回顾一下：

![](https://upload-images.jianshu.io/upload_images/4155986-dd3368c8ff9e6fe9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过一个**shallow tower（可理解为比较轻量的模型）**来预测位置偏置信息，输入的特征主要是一些和位置偏置相关的特征。在sigmoid前，将shallow tower的输出结果加入进去。而在预测阶段，则不考虑shallow tower的结果。

# 3、PAL框架

本文提出的消除位置偏置信息的框架称为Position-bias Aware Learning framework (PAL) 。其基于如下的假设，即用户点击广告的概率由两部分组成：广告被用户看到的概率和用户看到广告后，点击广告的概率。

![](https://upload-images.jianshu.io/upload_images/4155986-a4ee14e6309b4026.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

该假设可进一步进行化简，首先，用户是否看到广告只跟广告的位置有关系；其次，用户看到广告后，是否点击广告与广告的位置无关。此时公式可写作：

![](https://upload-images.jianshu.io/upload_images/4155986-16465be17c9d1425.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

基于该假设，就可以分开建模，PAL的框架如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-17e4da67593270c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，两个模块是联合进行训练的，如果分开进行优化，两个模块的训练目标不同，可能导致整个的系统是次优化的。

损失函数采用交叉熵损失：

![](https://upload-images.jianshu.io/upload_images/4155986-470318d532b34c15.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里再说一下，论文中并没有给出训练位置信息的模块所使用的特征，可以参考youtube论文中的思路，加入位置特征和上下文特征来训练。

# 4、实验结果

本文主要对比了下图中两个模型，左边是本文提出的PAL框架，右边是将位置信息作为输入特征的方法，作为BASE：

![](https://upload-images.jianshu.io/upload_images/4155986-4e47b219996cd52b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

来看下实验结果，首先看下离线训练结果。由于在测试集上，BASE方法需要一个固定位置，因此本文尝试了1-10位置作为固定位置时，BASE方法的效果和PAL方法的对比：

![](https://upload-images.jianshu.io/upload_images/4155986-10f5b5be6c544b08.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

从离线结果来看，PAL方法并非是最优的方法。接下来看线上的效果，文章对比了PAL和固定位置是1、5、9时BASE方法的结果：

![](https://upload-images.jianshu.io/upload_images/4155986-9363bea933ce6808.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

尽管离线训练的效果并非是最优的，但是PAL相较于BASE方法，线上效果取得了巨大的提升。

# 5、总结

本文提出了一种消除位置偏置对点击率预估影响的框架。该框架下，将位置信息当作一个单独的模块，而非作为一个输入特征进行训练，线上效果取得了巨大的提升。


# 推荐系统遇上深度学习(七十二)-[谷歌]采样修正的双塔模型

![](https://upload-images.jianshu.io/upload_images/4155986-04e48a29b5ee5783.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文题目是：《Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations》
论文下载地址是：https://dl.acm.org/citation.cfm?id=3346996

本文是谷歌工业风论文的新作，介绍了在大规模推荐系统中使用双塔模型来做召回的一些经验，值得细细品读。本文仅对文章内容做一个简单介绍，更多细节建议阅读原论文。

# 1、背景

大规模推荐系统一般分为两阶段，即召回和排序阶段，本文重点关注召回阶段。

给定{用户，上下文，物品}的三元组，一个通用的方法首先是分别计算{用户，上下文} 和 {物品} 的向量表示，然后通过一定的方式如点积来计算二者的匹配得分。这种基于表示学习的方法通常面临两个方面的挑战：

1）工业界中物品的数量十分巨大。
2）通过收集用户反馈得到的数据集十分稀疏，导致模型对于长尾物品的预测具有很大的方差，同时也面临着物品冷启动的问题。

近几年来，随着深度学习的发展，双塔模型常用来用做召回阶段的模型，双塔模型的一般结构如下：

![](https://upload-images.jianshu.io/upload_images/4155986-71be3ebbedc387ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，双塔模型两侧分别对{用户，上下文} 和 {物品} 进行建模，并在最后一层计算二者的内积。对于每一个正样本，需要随机采样一些负样本，当物品数量十分巨大的时候，上述结构的双塔模型很难得到充分训练。

那么如何对双塔模型进行一定的改进呢？本文主要提出了以下两个要点：通过**batch softmax optimization**来提升训练效率和通过**streaming frequency estimation**来修正**sampling bias**。

# 2、模型介绍

## 2.1 batch softmax optimization

假设训练集包含T条，物品数量为M：

![](https://upload-images.jianshu.io/upload_images/4155986-006fcae7f4fed128.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

x包括了用户特征和上下文特征，y则是物品特征，r是对应的label，x和y经过双塔模型得到对应的向量表示，分别记作u(x,θ)和v(y,θ)，并通过内积得到二者的相似性得分：

![](https://upload-images.jianshu.io/upload_images/4155986-608d819525706e9f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

那么给定一个x，从M个物品中选择对应y的概率可以经由下面的softmax方程得到：

![](https://upload-images.jianshu.io/upload_images/4155986-b7bc39cc9817654b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

损失函数如下：

![](https://upload-images.jianshu.io/upload_images/4155986-65737cbeff766580.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上述的做法相当于把该样本中的y作为正样本，其余所有的物品当作负样本。但是当M非常巨大时，使用所有的物品来计算softmax方程并不是十分合适。一种通用的做法是通过随机mini-batch的方式来优化损失函数。假设一个包含B条数据的mini-batch，那么对于任意一条数据，softmax计算公式如下：

![](https://upload-images.jianshu.io/upload_images/4155986-0fef92f3e4673db6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这种做法相当于把一个batch中此条数据之外物品当作负样本。但是这种做法存在的缺点就是会因为随机采样偏差而导致模型效果不好。对于热门物品来说，由于采样到的概率非常高，当作负样本的次数也会相应变多，热门物品会被“过度惩罚”。因此基于如下的公式对于x和y的评分进行一定程度的修正：

![](https://upload-images.jianshu.io/upload_images/4155986-a64d2d462780dc5d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上式中，p<sub>j</sub>代表第j条样本对应的物品y<sub>j</sub>被一个mini-batch采样到的概率，这在下一节会详细介绍。

那么此时，softmax计算公式变为：

![](https://upload-images.jianshu.io/upload_images/4155986-3b532f9b1454da93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而batch的损失函数计算如下：

![](https://upload-images.jianshu.io/upload_images/4155986-872ce6102feaa28a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

好了，整个的双塔模型训练过程再来回顾一下：

![](https://upload-images.jianshu.io/upload_images/4155986-0e9886b6b8fd3af8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中采样概率的预估算法，就是我们下一节要介绍的内容。

## 2.2 streaming frequency estimation

由于youtube中不断会有新物品出现，那么使用固定长度的词表不太合适，因此采用hash的方式来对物品的采样概率进行更新。

具体来说，假设有一个散列地址大小为H的hash函数h，对物品ID进行映射。同时使用两个长度为H的数组A和B，通过h(y)来得到其在数组A和B中下标。

那么，A[h(y)]记录上一次物品y被采样到的训练时刻，B[h(y)]记录物品y采样的预估频率（这里频率的意思是预估每过多少步可以被采样到一次，那么倒数就是预估被采样到的概率）。当第t步物品y被采样到，基于如下的公式更新B[h(y)]：

![](https://upload-images.jianshu.io/upload_images/4155986-28f3ae6be34204fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而A[h(y)]则被赋予当前的训练步骤t。当训练完成时，预估的物品y的采样概率是1/B[h(y)]。

完整的过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-6910946a065a4ae5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

既然是hash过程，当H<M时，就会存在冲突的情况。冲突的情况会导致B[h(y)]较小，因为t-A[h(y)]会较小。从而导致采样概率预估过高。这里的改进方案是使用multiple hashings。即使用多组hash方程和数组A和B。当训练完成时使用最大的一个B[h(y)]去计算采样概率。具体过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-6930ee02ffd3bc9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.3 Nearest Neighbor Search

当模型训练完成时，物品的embedding是可以保存成词表的，线上应用的时候只需要查找对应的embedding即可。因此线上只需要计算{用户，上下文}一侧的embedding，而基于hash技术（如局部敏感Hash）得到对应的候选集。

## 2.4 Normalization and Temperature

文中还介绍了双塔模型在使用时两点工业经验。

1）对两侧输出的embedding进行L2标准化，如：

![](https://upload-images.jianshu.io/upload_images/4155986-2dad2916c0bd362e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

2）对于内积计算的结果，除以一个固定的超参：

![](https://upload-images.jianshu.io/upload_images/4155986-209bc45e7f34550f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

除以超参的效果如下，可以看到softmax的效果更加明显：

![](https://upload-images.jianshu.io/upload_images/4155986-094d88e673942511.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

超参的设定可以通过实验结果的召回率或者精确率进行微调。

# 3、双塔模型应用于Youtube推荐

双塔模型应用于Youtube视频推荐的框架如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b16bf7a62ce051d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**训练Label**：这里训练集Label并不是点击即为1，未点击为0。而是当一个视频被点击但是观看时长非常短时，label同样是0。当视频被完整看完时，label才是1。

**视频侧特征**：视频侧包含的特征既有类别特征如视频ID、频道ID，也有连续特征。类别特征中有分为单值类别特征和多值类别特征，对于多值类别特征，采用对embedding加权平均的方式得到最终的embedding。

**用户侧特征**：用户侧特征主要是基于用户的历史观看记录来捕获用户的兴趣。比如使用用户最近观看过的k个视频的embedding的平均值。对于类别特征，embedding在模型的两侧是共享的。

**实时更新**：模型基于Tensorflow实现，并且进行了分布式实现。同时，模型会进行天级别更新。

# 4、实验结果

接下来，看一下几个关键的实验结果。

## 4.1 频率预估实验

对于实验设置，这里共有M个物品，每个物品的真实出现概率为q<sub>i</sub>，所有q<sub>i</sub>的和为1。在前一万步，q<sub>i</sub>正比于i<sup>2</sup>，在后一万步，q<sub>i</sub>正比于(M-1-i)<sup>2</sup>。如果每次采样B个物品，那么每个物品被采样到的概率为p<sub>i</sub>=q<sub>i</sub> * B，并作为label。而预测的概率则是刚才介绍的公式1/B[h(y)]，二者通过MAE计算误差。

使用不同的alpha来更新B，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-19efee99c83f22bf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，当alpha越来越小时，随着训练步数的增加，误差是越来越小的。

当使用不同数量的Hash方程时，误差如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b6cbc57d7e55aaf7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，使用更多的Hash方程数量，误差越小。

## 4.2 Youtube离线&在线实验

在youtube数据集上进行离线训练，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-b810a9108d398f09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中，plain-sfx表示不通过概率对采样偏差进行修正，correct-sfx表示修正采样偏差，可以看到修正后效果更为显著。线上结果同样如此：

![](https://upload-images.jianshu.io/upload_images/4155986-13e76bda539b6aa1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 5、总结

本文作为一篇工业实战类型的推荐文章，详细介绍了双塔模型在使用时的一些小技巧，一起简单来回顾下：

1）使用batch softmax optimization来训练模型。
2）使用frequency estimation来修正采样偏差，修正方法基于Multiple Hashings。
3）线上应用时使用hash等技术来提高检索效率。
4）对两侧得到的Embedding进行正则化。
5）通过对得到的内积除以一个超参数，使得softmax结果更加明显。

好了，本文就到这里了，大伙一定要去看原论文哟。



# 推荐系统遇上深度学习(七十三)-[微软]通过对抗训练消除位置偏置信息

![](https://upload-images.jianshu.io/upload_images/4155986-8b79aed1de322bae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文是：《Modeling and Simultaneously Removing Bias via Adversarial Neural Networks》

前面已经有几篇关于消除CTR预估中位置偏置信息的介绍，如华为的PAL、youtube的shallow tower、以及将位置信息作为输入特征的方法。但对于样本中可能存在的偏置信息，上述的方法都没有解决，而本文提出的对抗学习框架，不仅解决了一般的位置偏置，还能够消除样本特征中的偏置信息，一起来学习一下吧。

# 1、背景

对于搜索广告的排序，往往是基于对于广告点击率的预估以及广告主的出价（bid）来决定的。但是用于训练点击率预估模型的样本中，往往存在一定的偏置信息。

在训练点击率预估模型时，许多特征属于统计特征，比如搜索关键词和广告的交叉点击率。对于经常展示的关键词／广告对来说，这类特征比较丰富且置信，但是对于不经常展示或者从未展示过的关键词／广告对来说，这类信息非常稀疏且不置信，模型对这些关键词／广告的信息不能充分学习，很难将这些关键词／广告对的展示位置进行提前。

同时，当CTR模型进行更新时，所使用的数据往往是在线上应用前一版模型而收集到的。新的数据和模型更容易学到这些展示位置靠前的关键词／广告对的信息，这种情形文中称为“Feedback Loop”，此时我们的训练所使用的数据，是存在一定偏置信息的。

这种偏置信息的存在，大都集中于位置偏置，即不同的展示位置对于CTR的影响不同，越靠前位置展示的广告，点击率会偏高。因此有必要在模型训练的过程中消除这些信息。

关于位置偏置信息的消除，前面几篇论文中已经提到过几种方法了，简单回顾一下：

**位置信息作为特征**

![](https://upload-images.jianshu.io/upload_images/4155986-77d75338536b7ec7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**华为PAL框架**

![](https://upload-images.jianshu.io/upload_images/4155986-17e4da67593270c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**Youtube Shallow-Tower**

![](https://upload-images.jianshu.io/upload_images/4155986-dd3368c8ff9e6fe9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

但上面几种方法虽然在一定程度上解决了位置偏置信息，但是样本中的偏置信息没有解决，举个简单的例子，比如某用户和某个品类的点击率交叉特征，这个特征本身也是存在偏置的，有可能某种品类的展示位置靠前导致了用户对于这种品类的商家点击率特别高。

本文提出的对抗学习框架，不仅解决了一般的位置偏置信息，还能够消除样本特征中的偏置信息，一起来学习一下吧。

# 2、对抗学习框架

## 2.1 框架介绍

对抗学习（Adversarial Neural Network）的框架如下图所示：

![](https://upload-images.jianshu.io/upload_images/4155986-6d9564b8d2df2f5c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

模型一共包含四个部分，BaseNet、Bypass Net、Prediction Net和Bias Net。

对于ByPass Net，输入是该样本对应位置的点击率b，定义为P(y|Position = p) 。通过参数Θ<sub>BY</sub>得到输出Z<sub>BY</sub>，这里类似于youtube的shallow tower，但输入特征只有一个该位置的点击率。

再看看另一侧，输入是特征X，输入特征首先经过Base Net，对应参数为Θ<sub>A</sub>，得到输出Z<sub>A</sub>。

得到Z<sub>A</sub>之后，会经过两个Net，第一个是Bias Net，对应的参数为Θ<sub>B</sub>，该网络的输出为该样本对应的位置预测点击率，前面说了，由于Feedback Loop的存在，输入特征中是存在一定的偏置信息，那么基于这些特征，是可以学习到一定的偏置信息的。

第二个是Prediction Net，对应的参数为Θ<sub>Y</sub>，得到输出Z<sub>Y</sub>。

## 2.2 对抗训练过程

接下来我们介绍下对抗训练的过程，主要分为两步。

首先看看对于Bias Net的训练。这一步我们固定其他几个网络的参数，只更新Bias Net的参数Θ<sub>B</sub>，对应的损失函数为：

![](https://upload-images.jianshu.io/upload_images/4155986-6e91326fcfab3a88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里我们期望Bias Net能对Base Net得到的输出，能够准确得到其中包含的偏置信息。

当Bias Net训练一轮之后，保持Θ<sub>B</sub>不变，再训练剩下的网络参数Θ<sub>A</sub>、Θ<sub>Y</sub>和Θ<sub>BY</sub>，此时的损失为：

![](https://upload-images.jianshu.io/upload_images/4155986-534c681a8edbc581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，损失的第一部分是logloss：

![](https://upload-images.jianshu.io/upload_images/4155986-1c3159184c7bfd9b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

第二部分是将此时Base Net所得到的输出，输入到参数固定的Bias Net中，所得到的预测值，和实际样本的位置点击率b的协方差的平方：

![](https://upload-images.jianshu.io/upload_images/4155986-90826ef4ae3b6488.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

当二者完全不相关时，第二部分的损失是最小的。

好了，对抗学习的思路是如何体现的呢？这里简单说下我的理解。Bias Net相当于GAN中的D，剩余三部分可以看作是G。我们期望Bias Net能够准确识别输入中的偏置信息，而通过剩余三部分的训练，期望Base Net输出的Z<sub>A</sub>能够骗过Bias Net，如果无法骗过Bias Net，那么Bias Net得到的输出和实际样本的位置点击率b的协方差的平方会比较大，导致整个G的损失增大。如果能够骗过Bias Net，使Bias Net得到的输出和实际样本的位置点击率b的协方差尽可能接近0，那么此时可以认为Base Net输出的Z<sub>A</sub>中偏置信息基本被消除了。

基于上述介绍，整个对抗网络的训练过程如下：

![](https://upload-images.jianshu.io/upload_images/4155986-0684f286c8286612.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 2.3 线上应用 

那么在线上应用时，只运用Base Net、Prediction Net和Bypass Net。而Bypass Net的输入设置为位置1的位置点击率。

# 3、实验结果

有关实验结果，论文中使用的是仿真实验的方式，这里就不再细讲，感兴趣的同学可以看下原论文。



# 推荐系统遇上深度学习(七十四)-[天猫]MIND：多兴趣向量召回

![](https://upload-images.jianshu.io/upload_images/4155986-535483dc9a09d4aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文介绍的论文是：《Multi-Interest Network with Dynamic Routing for Recommendation at Tmall》

关于召回阶段的算法，以youtube DNN为代表的向量化召回方式是目前的主流算法之一，但是目前的大多数算法仅仅将用户的兴趣表示成单个的Embedding，这是不足以表征用户多种多样的兴趣的，同时容易造成头部效应。因此本文提出了MIND，同时生成多个表征用户兴趣的Embedding，来提升召回阶段的效果，一起来学习一下。

# 1、背景

在天猫的推荐过程中，推荐系统也被拆分为召回和排序阶段。

![](https://upload-images.jianshu.io/upload_images/4155986-8a65396dfb13c5ab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

本文重点关注召回阶段的算法。召回阶段的目标是得到数千个跟用户兴趣紧密相关的商品候选集。在天猫场景下，用户每天都要与成百上千的商品发生交互，用户的兴趣表现得多种多样。如下图所示，不同的用户之间兴趣不相同，同时同一个用户也会表现出多样的兴趣：

![](https://upload-images.jianshu.io/upload_images/4155986-424cfca20b0e4695.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因此，对于用户兴趣的建模显得至关重要。目前召回阶段主流的算法是协同过滤和向量化召回。协同过滤面临稀疏性的问题。而向量化召回方法如youtube dnn，将用户的兴趣表示成一个固定长度的向量。

但在天猫场景下，对于用户多样化的兴趣，一个Embedding往往是不够的，除非这个Embedding的长度足够大，具有足够的表征能力。除此之外，只有一个Embedding会造成一定的头部效应，召回的结果往往是比较热门领域的商品（头部问题），对于较为小众领域的商品，召回能力不足。

解决上述问题的方法也很简单，搞多个用户Embedding就好了嘛，而本文要介绍的MIND，正是通过生成多个表征用户兴趣的Embedding，来提升召回阶段的效果，一起来学习一下。（昨天听了俊林老师的讲座，这个方向也是他比较看好的）

# 2、MIND

## 2.1 问题概述

召回阶段的目标是对于每个用户u∈U的请求，从亿级的商品池I中，选择成百上千的符合用户兴趣的商品候选集。每条样本可以表示成三元组（I<sub>u</sub>,P<sub>u</sub>,F<sub>i</sub>)，其中I<sub>u</sub>是用户u历史交互过的商品集合，P<sub>u</sub>是用户画像信息，比如年龄和性别，F<sub>i</sub>是目标商品的特征，如商品ID、商品品类ID。

那么MIND的核心任务是将用户相关的特征转换成一系列的用户兴趣向量：

![](https://upload-images.jianshu.io/upload_images/4155986-d10c8db85d86c980.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](https://upload-images.jianshu.io/upload_images/4155986-f3bf6398ab9028b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而目标商品向量F<sub>i</sub>也被转换为一个Embedding：

![](https://upload-images.jianshu.io/upload_images/4155986-ec27bc83338b42b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

当得到用户和商品的向量表示之后，通过如下的score公式计算得到topN的商品候选集：

![](https://upload-images.jianshu.io/upload_images/4155986-3545209daeb170e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

整个MIND的框架如下：

![](https://upload-images.jianshu.io/upload_images/4155986-81cd39dd100c71d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来，详细介绍MIND中的各部分。

## 2.2 Embedding Layer

如上图，MIND的输入中包含三部分，用户的画像信息P<sub>u</sub>、用户历史行为I<sub>u</sub>和目标商品F<sub>i</sub>。每个部分都包含部分的类别特征，类别特征会转换为对应的embedding。对用户画像信息部分来说，不同的embedding最终拼接在一起。而对于用户历史行为I<sub>u</sub>中的商品和目标商品F<sub>i</sub>来说，商品ID、品牌ID、店铺ID等转换为embedding后会经过avg-pooling layer来得到商品的embedding表示。

## 2.3 Multi-Interest Extractor Layer

接下来是最为关键的 Multi-Interest Extractor Layer，这里借鉴的是Hiton提出的胶囊网络。有关胶囊网络，下面的图可以帮助你快速理解（图片来源于知乎：https://zhuanlan.zhihu.com/p/68897114）：

![](https://upload-images.jianshu.io/upload_images/4155986-d88e7ba2ea9b778e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，胶囊网络和传统的神经网络较为类似。传统神经网络输入一堆标量，首先对这堆标量进行加权求和，然后通过非线性的激活函数得到一个标量输出。而对胶囊网络来说，这里输入的是一堆向量，首先对这组向量进行仿射变换，然后进行加权求和，随后通过非线性的"squash"方程进行变换，得到另一组向量的输出。

而MIND中的Multi-Interest Extractor Layer，与胶囊网络主要有两个地方不同：

1）在胶囊网络中，每一个输入向量和输出向量之间都有一个单独的仿射矩阵，但是MIND中，仿射矩阵只有一个，所有向量之间共享同一个仿射矩阵。主要原因是用户的行为数量长度不同，使用共享的仿射矩阵不仅可以减少参数，同时还能对应另一处的改变，即不同用户输出向量的个数K是基于他历史行为长度自适应计算的：

![](https://upload-images.jianshu.io/upload_images/4155986-8b443539cb9fe3f5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上面基于用户历史行为长度自适应计算输出向量个数K'的策略，对于那些交互行为较少的用户来说，可以减少这批用户的存储资源。

2）为了适应第一个改变，胶囊网络中权重的初始化由全部设置为0变为基于正太分布的初始化。

下图是整个Multi-Interest Extractor Layer的过程：

![](https://upload-images.jianshu.io/upload_images/4155986-fb532f6125caeecd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过Multi-Interest Extractor Layer，得到了多个用户向量表示。接下来，每个向量与用户画像embedding进行拼接，经过两层全连接层（激活函数为Relu）得到多个用户兴趣向量表示。每个兴趣向量表征用户某一方面的兴趣。

## 2.4 Label-aware Attention Layer

在上一步得到用户兴趣向量之后，由于不同用户的兴趣向量个数不同，通过Label-aware Attention Layer对这些向量进行加权（只应用于训练阶段），类似DIN中的做法：

![](https://upload-images.jianshu.io/upload_images/4155986-c801e9d29865655b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而计算公式为：

![](https://upload-images.jianshu.io/upload_images/4155986-34755b40e1e6c9d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图中的Q相当于目标商品的embedding，K和V都是用户的兴趣向量。值得注意的一点是，在softmax的时候，对得到的attention score，通过指数函数进行了一定的缩放。当p接近0时（这里应该是假设了向量的内积大于1吧），对softmax是一种平滑作用，使得各attention score大小相近，当p>1且不断增加时，对softmax起到的是一种sharpen作用，attention score最大那个兴趣向量，在sofamax之后对应的权重越来越大，此时更类似于一种hard attention，即直接选择attention score最大的那个向量。实验表明hard attention收敛速度更快。

## 2.5 Training & Serving

在训练阶段，使用经过Label-aware Attention Layer得到的用户向量和目标商品embedding，计算用户u和商品i交互的概率（这里和youtube DNN相似，后文中说也进行了采样）：

![](https://upload-images.jianshu.io/upload_images/4155986-45ca3d2b3978271c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而目标函数（而非损失函数）为：

![](https://upload-images.jianshu.io/upload_images/4155986-d86b90345b189a88.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而在线上应用阶段，只需要计算用户的多个兴趣向量，然后每个兴趣向量通过最近邻方法（如局部敏感哈希LSH）来得到最相似的候选商品集合。同时，当用户产生了一个新的交互行为，MIND也是可以实时响应得到用户新的兴趣向量的。

# 3、实验结果

接下来看下实验结果。

对于离线实验，文中使用MIND和BASE模型（如youtube DNN）等进行了对比，结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-8e5ed79027795d3d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而在线上实验时，为了进行对比，不同的召回模型都使用同样的排序模型作为下游，并比较了一周内不同实验组的CTR：

![](https://upload-images.jianshu.io/upload_images/4155986-cd9fbd5b0c8d0ad3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以看到，无论是线上还是线下实验，MIND都取得了不错的效果。

# 4、总结

目前召回阶段，有几个值得不错的方向，比如MIND中的用户兴趣多Embedding拆分和基于Graph的召回，大伙不妨可以尝试一下。



# 推荐系统遇上深度学习(七十五)-考虑CPM的评估方法csAUC

![](https://upload-images.jianshu.io/upload_images/4155986-6cae4749aaa69e52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 1、背景

在点击率预估中，AUC是最常用的评估指标，这一指标衡量的是任取一个正例和负例，正例的得分高于负例的概率。那么点击率预估中，正例和负例分别是什么呢？很显然，正例就是用户点击过的item，负例是用户没有点击的item。

但是在广告排序场景下，线上排序通常考虑收益最大化，通过CTR * Bid进行排序，而非仅仅通过CTR进行排序。如果线下仅仅通过AUC来评价离线模型的效果，你往往会发现，线下的AUC涨了，但是线上的收入eCPM（千次广告展示收入）却降了。这是因为线下AUC的评估仅考虑点击率CTR，而线上展示不仅考虑了CTR，同时考虑了广告主的出价BID，二者之间存在一定的gap。

因此，本文提出了考虑CPM的评估方法csAUC，下文中我们先回顾一下AUC的定义，再介绍csAUC。

# 2、AUC回顾

**混淆矩阵**
我们首先来看一下混淆矩阵，对于二分类问题，真实的样本标签有两类，我们学习器预测的类别有两类，那么根据二者的类别组合可以划分为四组，如下表所示：

![](https://upload-images.jianshu.io/upload_images/4155986-31296ad3c9f891e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上表即为**混淆矩阵**，其中，行表示预测的label值，列表示真实label值。TP，FP，FN，TN分别表示如下意思：

**TP（true positive）**：表示样本的真实类别为正，最后预测得到的结果也为正；
**FP（false positive）**：表示样本的真实类别为负，最后预测得到的结果却为正；
**FN（false negative）**：表示样本的真实类别为正，最后预测得到的结果却为负；
**TN（true negative）**：表示样本的真实类别为负，最后预测得到的结果也为负.

想要计算AUC，我们通常先绘制ROC曲线，ROC曲线的横轴为“假正例率”（False Positive Rate,FPR)，又称为“假阳率”；纵轴为“真正例率”(True Positive Rate,TPR)，又称为“真阳率”，

**假阳率**，简单通俗来理解就是预测为正样本但是预测错了的可能性：

![](https://upload-images.jianshu.io/upload_images/4155986-6a7aa2038eb2cbee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**真阳率**，则是代表预测为正样本但是预测对了的可能性：

![](https://upload-images.jianshu.io/upload_images/4155986-d4d8eda66f1169ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

ROC计算过程如下：
1)首先每个样本都需要有一个label值，并且还需要一个预测的score值（取值0到1）;
2)然后按这个score对样本由大到小进行排序，假设这些数据位于表格中的一列，从上到下依次降序;
3)现在从上到下按照样本点的取值进行划分，位于分界点上面的我们把它归为预测为正样本，位于分界点下面的归为负样本;
4)分别计算出此时的TPR和FPR，然后在图中绘制（FPR, TPR）点。

说这么多，不如直接看图来的简单：

![](http://upload-images.jianshu.io/upload_images/4155986-0c24244b8e8c01b7.gif?imageMogr2/auto-orient/strip)

AUC（area under the curve）就是ROC曲线下方的面积，如下图所示，阴影部分面积即为AUC的值：

![](https://upload-images.jianshu.io/upload_images/4155986-84670734192f9b0d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

AUC量化了ROC曲线表达的分类能力。这种分类能力是与概率、阈值紧密相关的，分类能力越好（AUC越大），那么输出概率越合理，排序的结果越合理。

AUC还有一个很有趣的性质，它和Wilcoxon-Mann-Witney是等价的，而Wilcoxon-Mann-Witney Test就是**测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score**。

根据这个定义我们可以来探讨一下二者为什么是等价的？首先我们偷换一下概念，其实意思还是一样的，**任意给定一个负样本，所有正样本的score中有多大比例是大于该负类样本的score？** 那么对每个负样本来说，有多少的正样本的score比它的score大呢？是不是就是**当结果按照score排序，阈值恰好为该负样本score时的真正例率TPR**？理解到这一层，二者等价的关系也就豁然开朗了。**ROC曲线下的面积或者说AUC的值 与 测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score**是等价的。基于此，我们可以得到AUC的计算公式：

![](https://upload-images.jianshu.io/upload_images/4155986-7b554bfc12d8d180.png?imageMogr2/auto-orient/strip|imageView2/2/w/690)

上式中，统计一下所有的 M×N(M为正类样本的数目，N为负类样本的数目)个正负样本对中，有多少个组中的正样本的score大于负样本的score。当二元组中正负样本的 score相等的时候，按照0.5计算。然后除以MN。

# 3、CPM-sensitive AUC

好了，回顾完AUC，本节介绍一下CPM-sensitive AUC（简称csAUC），这里，我们首先要对样本的级别进行划分

**样本级别是多层次的**：AUC中样本仅有正例负例之分，但是在csAUC中，样本的排序是多层次的，负例是的level是最低的（lowest），而正例会按照其对应的bid进行排序，正例的bid越高，其level也是越高的。

给定一个high-level的样本x<sub>h</sub>和low-level的样本x<sub>l</sub>，定义收益（Rev）如下：

![](https://upload-images.jianshu.io/upload_images/4155986-bf9641729371c9ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

而整个样本集D中的csAUC计算如下：

![](https://upload-images.jianshu.io/upload_images/4155986-bb7d19a5781af152.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于一个给定的样本集D，csAUC的分母是确定的，对于分子来说，如果训练得到的模型没有将出价高的正样本排在出价低的正样本或者将负样本排在正样本前面的话，都会造成损失（分子减小），当两个正样本的出价相差越大，或者正样本出价越高（一正一负的情况），造成的损失越大。因此csAUC不仅希望正样本能够排在负样本前面，而且希望出价高的正样本排序能够更靠前。

# 4、csAUC分析

下面给出一个例子对AUC和csAUC进行分析，样例如下：

![](https://upload-images.jianshu.io/upload_images/4155986-ab667093cfa90bad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

接下来给出六个模型，每个模型得到的排序结果如下：

![](https://upload-images.jianshu.io/upload_images/4155986-01b89b42f3cbfd1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

各组结果的AUC及csAUC如下：

![](https://upload-images.jianshu.io/upload_images/4155986-fffca7fb9fd4f235.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里咱们一起来算下第一组结果的csAUC：

![](https://upload-images.jianshu.io/upload_images/4155986-ea0c8578c2234293.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

对于AUC来说，由于有M个正样本和N个负样本，因此构成的样本对只有M*N个(本例是4 * 1=4），但是对于csAUC来说，其样本对有10个（正样本里随机选两个的选法C<sup>2</sup><sub>M</sub> + M * N，本例是C<sup>2</sup><sub>4</sub> + 4 * 1 = 10）

可以看到，只要把所有正样本排在负样本前面，AUC都是1，所以只评价AUC的话，前4个模型的离线效果是相同的。但是第一个模型把出价最高的A排在了正样本的最后，造成了很多收益损失，所以其csAUC最低。

好了，本文的csAUC就介绍到这里了，对于此感兴趣的同学可以尝试一下哟～～

